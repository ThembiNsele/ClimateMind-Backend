{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File pvq21_REVERSED_CENTRED.csv does not exist: 'pvq21_REVERSED_CENTRED.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-feca138ab93d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pvq21_REVERSED_CENTRED.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mlib_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mcon_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File pvq21_REVERSED_CENTRED.csv does not exist: 'pvq21_REVERSED_CENTRED.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv(\"../datasets/pvq21_REVERSED_CENTRED.csv\", sep=',')\n",
    "lib_dataframe = data.copy()\n",
    "con_dataframe = data.copy()\n",
    "\n",
    "ub_dataframe = data.copy()\n",
    "((ub_dataframe[ub_dataframe['lrscale'] > 7].shape[0])/ ub_dataframe.shape[0]) *100\n",
    "\n",
    "\n",
    "lrscale_balanced = ub_dataframe['lrscale']\n",
    "\n",
    "# print(ub_dataframe[ub_dataframe['lrscale'] == 7].shape[0])\n",
    "\n",
    "lrscale_balanced.hist(bins=11, figsize=[14,6])\n",
    "\n",
    "print(ub_dataframe.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing the data\n",
    "Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Randomise dataframe\n",
    "2. counter variable = 0\n",
    "3. Go through the dataframe       *Or actually just pick all instances over this lr threshold* \n",
    "    3.1 For ever lrscore > threshold\n",
    "        3.2 Add to a new dataframe\n",
    "        3.3 counter ++ \n",
    "     \n",
    "4. While the new (balancer) dataframe is <= to the 50% of length of the full dataframe \n",
    "\n",
    "    4.1 Copy to itself\n",
    "    \n",
    "    \n",
    "5. Attach balancer dataframe to the previous data frame\n",
    "6. Return new dataframe \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36360\n",
      "(36360, 13)\n"
     ]
    }
   ],
   "source": [
    "#Some exploration:\n",
    "print(len(ub_dataframe))\n",
    "print(ub_dataframe.shape)\n",
    "\n",
    "\n",
    "def balance_samples(unbalanced_dataframe, lrthreshold):\n",
    "    \"\"\"Return a balanced dataframe i.e. consisting at 50% of the examples/cases above the lrthreshold (not inclusive)\"\"\"\n",
    "    balancer_dataframe = pd.DataFrame()\n",
    "\n",
    "    balancer_dataframe = unbalanced_dataframe[unbalanced_dataframe['lrscale'] > lrthreshold].copy()\n",
    "\n",
    "    #Calculate the 50% \n",
    "    half_value = int(len(unbalanced_dataframe)/2)\n",
    "\n",
    "\n",
    "    #The difference to getting a number of samples equal to 50 % of the original dataset\n",
    "   # dif_half = half_value - len(balancer_dataframe)\n",
    "\n",
    "    copy_balancer_dataframe = balancer_dataframe.sample(n = half_value, replace=True).reset_index(drop=True)\n",
    "    \n",
    "    balancer_dataframe = pd.concat([balancer_dataframe,copy_balancer_dataframe], axis=0)\n",
    "\n",
    "    balanced_df = pd.concat([unbalanced_dataframe,balancer_dataframe], axis=0)\n",
    "\n",
    "    balanced_df = balanced_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    return balanced_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersample(unbalanced_dataframe, lrthreshold, skew_distribution = 0.5):\n",
    "    \"\"\"Return a balanced dataframe i.e. consisting at 50% of the examples/cases above the lrthreshold (inclusive)\"\"\"\n",
    "    balancer_dataframe = unbalanced_dataframe.copy()\n",
    "    #balancer_data\n",
    "    minority_df = balancer_dataframe[balancer_dataframe['lrscale'] > lrthreshold]\n",
    "    minority_count = minority_df.shape[0]\n",
    "\n",
    "    print(\"minority_count\", minority_count)\n",
    "\n",
    "    print(\"TESTHOWMANY??\", balancer_dataframe[balancer_dataframe['lrscale'] <= lrthreshold].shape[0])\n",
    "    #pick and remove a random sample of instances under the set threshold\n",
    "    majority_balancer = balancer_dataframe[balancer_dataframe['lrscale'] <= lrthreshold].sample(n=minority_count, replace = False)\n",
    "    \n",
    "    balanced_df = pd.concat([minority_df,majority_balancer],axis=0)\n",
    "    balanced_df = balanced_df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "#     print(\"majority balancer\", majority_balancer.shape[0])\n",
    "#     print(\"minority df\", minority_df.shape[0])\n",
    "#     print(\"balanced df\", balanced_df.shape[0])\n",
    "\n",
    "    \n",
    "    return balanced_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_count 9391\n",
      "TESTHOWMANY?? 26969\n"
     ]
    }
   ],
   "source": [
    "lrthreshold = 6\n",
    "# print(con_dataframe.head())\n",
    "balanced_dataframe = undersample(ub_dataframe, lrthreshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_count 9391\n",
      "TESTHOWMANY?? 26969\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "undersampled_dataframe = undersample(ub_dataframe,lrthreshold)\n",
    "\n",
    "\n",
    "\n",
    "print(type(balanced_dataframe))\n",
    "print(type(undersampled_dataframe))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18782, 12)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576000x72000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(undersampled_dataframe.shape)\n",
    "\n",
    "# balanced_dataframe[balanced_dataframe['lrscale'] > 7].shape[0]\n",
    "# lrscale_balanced = undersampled_dataframe['lrscale']\n",
    "# lrscale_balanced.hist(bins=10, figsize=[14,6])\n",
    "\n",
    "def hist_plotter(dataframe,threshold):\n",
    "    lrscale_balanced = dataframe['lrscale']\n",
    "    n,bins,patches = plt.hist(lrscale_balanced, bins=[0, 1, 2, 3, 4, 5, 6,7,8,9,10], color='b')\n",
    "    plt.title(f\"Distribution on threshold > {threshold}\") \n",
    "    plt.figure(figsize=(8000,1000))\n",
    "    \n",
    "    for patch_num in range(threshold, 10):\n",
    "        patches[patch_num].set_fc('g')\n",
    "\n",
    "hist_plotter(undersampled_dataframe,lrthreshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percenatge of scores over 6  50.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"The percenatge of scores over {lrthreshold} \",((undersampled_dataframe[undersampled_dataframe['lrscale'] > lrthreshold].shape[0]) / undersampled_dataframe.shape[0])*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   lrscale  universalism  achievement  benevolence  self_direction  \\\n",
      "0        5          4.90     2.066667     4.566667        2.566667   \n",
      "1        6          4.00     2.000000     4.500000        3.000000   \n",
      "2        7          2.75     3.583333     4.083333        5.083333   \n",
      "3        3          4.35     5.016667     4.016667        4.516667   \n",
      "4        7          4.55     2.550000     4.050000        4.050000   \n",
      "\n",
      "   stimulation  hedonism     power  security  conformity  tradition     p_avg  \n",
      "0     2.066667  3.566667  1.566667  4.566667    4.566667   4.566667  3.933333  \n",
      "1     2.000000  4.000000  3.000000  4.000000    4.000000   4.500000  3.500000  \n",
      "2     3.083333  3.583333  3.083333  2.583333    2.583333   4.583333  3.416667  \n",
      "3     3.516667  3.516667  2.516667  3.016667    1.016667   3.516667  4.483333  \n",
      "4     1.550000  3.050000  2.550000  4.550000    3.550000   4.550000  4.950000  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(balanced_dataframe.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the (almost) balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_dataframe = undersampled_dataframe.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18782, 12)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_dataframe.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bin the data for each dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_lib (value):\n",
    "\n",
    "        if value < 3:\n",
    "            return 1#\"liberal\" #liberal\n",
    "        else:\n",
    "            return 0#\"moderate\" #moderate\n",
    "\n",
    "def normalise_con (value):\n",
    "        \n",
    "        if value > lrthreshold:\n",
    "            return 1#\"conservative\" #conservative\n",
    "        else:\n",
    "            return 0#\"moderate\" #moderate\n",
    "        \n",
    "\n",
    "lib_dataframe['lrscale'] = lib_dataframe['lrscale'].apply(normalise_lib)\n",
    "con_dataframe['lrscale'] = con_dataframe['lrscale'].apply(normalise_con)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   universalism  achievement  benevolence  self_direction  stimulation  \\\n",
      "0          5.50     4.500000     5.500000        4.000000     3.500000   \n",
      "1          4.80     4.133333     4.633333        4.633333     3.133333   \n",
      "2          4.65     1.650000     4.650000        4.150000     0.650000   \n",
      "3          3.60     3.433333     3.433333        3.933333     2.933333   \n",
      "4          4.45     2.616667     5.116667        4.116667     2.116667   \n",
      "\n",
      "   hedonism     power  security  conformity  tradition  \n",
      "0  3.000000  3.000000  2.500000    1.000000   2.500000  \n",
      "1  3.133333  3.133333  2.633333    2.133333   2.633333  \n",
      "2  4.150000  2.650000  5.650000    2.650000   4.150000  \n",
      "3  3.933333  3.433333  3.933333    2.433333   3.933333  \n",
      "4  5.116667  2.616667  2.616667    2.616667   3.616667  \n",
      "0    0\n",
      "1    1\n",
      "2    5\n",
      "3    0\n",
      "4    5\n",
      "Name: lrscale, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_lib = lib_dataframe.iloc[:, 1:11].copy()\n",
    "y_lib = lib_dataframe.iloc[:,0].copy()\n",
    "#Now the data frame for conservative prediction\n",
    "X_con = con_dataframe.iloc[:, 1:11].copy()\n",
    "y_con = con_dataframe.iloc[:,0].copy()\n",
    "\n",
    "print(X_con.head())\n",
    "print(y_con.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9391\n",
      "9391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list(y_con).count(1))\n",
    "print(list(y_con).count(0))\n",
    "\n",
    "con_lib_ratio = (list(y_con).count(1)/(list(y_con).count(0) + list(y_con).count(1)) * 100)\n",
    "con_lib_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(sparse=False)\n",
    "y_lib_onehot = enc.fit_transform(y_lib.to_numpy().reshape(-1, 1))\n",
    "y_con_onehot = enc.fit_transform(y_con.to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Encoding instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_lib_onehot = label_encoder.fit_transform(y_lib.copy())\n",
    "y_con_onehot = label_encoder.fit_transform(y_con.copy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lib_oh, X_test_lib_oh, y_train_lib_oh, y_test_lib_oh = train_test_split(X_lib, y_lib_onehot, test_size=0.25, random_state=10)\n",
    "X_train_con_oh, X_test_con_oh, y_train_con_oh, y_test_con_oh = train_test_split(X_con, y_con_onehot, test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>universalism</th>\n",
       "      <th>achievement</th>\n",
       "      <th>benevolence</th>\n",
       "      <th>self_direction</th>\n",
       "      <th>stimulation</th>\n",
       "      <th>hedonism</th>\n",
       "      <th>power</th>\n",
       "      <th>security</th>\n",
       "      <th>conformity</th>\n",
       "      <th>tradition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17160</th>\n",
       "      <td>4.15</td>\n",
       "      <td>4.150000</td>\n",
       "      <td>4.650000</td>\n",
       "      <td>2.150000</td>\n",
       "      <td>2.650000</td>\n",
       "      <td>3.650000</td>\n",
       "      <td>3.150000</td>\n",
       "      <td>3.650000</td>\n",
       "      <td>3.650000</td>\n",
       "      <td>3.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25515</th>\n",
       "      <td>3.60</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>3.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8023</th>\n",
       "      <td>4.50</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24390</th>\n",
       "      <td>4.15</td>\n",
       "      <td>3.983333</td>\n",
       "      <td>3.983333</td>\n",
       "      <td>3.483333</td>\n",
       "      <td>2.483333</td>\n",
       "      <td>2.483333</td>\n",
       "      <td>3.983333</td>\n",
       "      <td>2.983333</td>\n",
       "      <td>3.983333</td>\n",
       "      <td>3.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17502</th>\n",
       "      <td>4.50</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>3.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10201</th>\n",
       "      <td>4.65</td>\n",
       "      <td>3.150000</td>\n",
       "      <td>5.150000</td>\n",
       "      <td>5.150000</td>\n",
       "      <td>1.150000</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>2.650000</td>\n",
       "      <td>4.650000</td>\n",
       "      <td>2.650000</td>\n",
       "      <td>4.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9372</th>\n",
       "      <td>4.30</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>4.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28017</th>\n",
       "      <td>4.60</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>2.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29199</th>\n",
       "      <td>3.50</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17673</th>\n",
       "      <td>4.95</td>\n",
       "      <td>3.783333</td>\n",
       "      <td>4.283333</td>\n",
       "      <td>4.283333</td>\n",
       "      <td>3.783333</td>\n",
       "      <td>3.283333</td>\n",
       "      <td>3.283333</td>\n",
       "      <td>2.783333</td>\n",
       "      <td>2.783333</td>\n",
       "      <td>1.783333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27270 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       universalism  achievement  benevolence  self_direction  stimulation  \\\n",
       "17160          4.15     4.150000     4.650000        2.150000     2.650000   \n",
       "25515          3.60     4.100000     4.100000        4.100000     2.600000   \n",
       "8023           4.50     2.666667     3.666667        4.166667     2.166667   \n",
       "24390          4.15     3.983333     3.983333        3.483333     2.483333   \n",
       "17502          4.50     2.833333     3.833333        3.833333     2.333333   \n",
       "...             ...          ...          ...             ...          ...   \n",
       "10201          4.65     3.150000     5.150000        5.150000     1.150000   \n",
       "9372           4.30     3.300000     3.800000        3.800000     1.800000   \n",
       "28017          4.60     3.100000     4.600000        4.600000     4.600000   \n",
       "29199          3.50     3.166667     4.166667        4.666667     3.166667   \n",
       "17673          4.95     3.783333     4.283333        4.283333     3.783333   \n",
       "\n",
       "       hedonism     power  security  conformity  tradition  \n",
       "17160  3.650000  3.150000  3.650000    3.650000   3.150000  \n",
       "25515  2.600000  3.600000  3.600000    3.100000   3.600000  \n",
       "8023   3.666667  1.666667  4.166667    4.166667   4.166667  \n",
       "24390  2.483333  3.983333  2.983333    3.983333   3.483333  \n",
       "17502  2.833333  2.333333  4.833333    3.833333   3.833333  \n",
       "...         ...       ...       ...         ...        ...  \n",
       "10201  1.650000  2.650000  4.650000    2.650000   4.150000  \n",
       "9372   4.300000  1.300000  4.800000    3.300000   4.300000  \n",
       "28017  4.100000  2.100000  2.100000    2.600000   2.600000  \n",
       "29199  2.166667  4.166667  3.166667    4.166667   2.666667  \n",
       "17673  3.283333  3.283333  2.783333    2.783333   1.783333  \n",
       "\n",
       "[27270 rows x 10 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tup = (X_train_con_oh, y_train_con_oh)\n",
    "\n",
    "tup[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call this function to perform cross validation to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(model):\n",
    "    #return scores\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "      normalize=False, positive=False, precompute=False, random_state=None,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class Lasso():\n",
    "lasso_LIB_model = Lasso(alpha=1.0)\n",
    "#fitting the liberal model\n",
    "lasso_LIB_model.fit(X_train_lib_oh,y_train_lib_oh)\n",
    "\n",
    "lasso_CON_model = Lasso(alpha=1.0)\n",
    "lasso_CON_model.fit(X_train_con_oh,y_train_con_oh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49943206 0.50056794]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:434: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lasso_lib_pred = lasso_LIB_model.predict(X_test_lib_oh)\n",
    "# print(lasso_lib_pred)\n",
    "\n",
    "#enc.inverse_transform([np.argmax(lasso_lib_pred[0, :])])\n",
    "# #print(lasso_lib_pred[0, :])\n",
    "# print(\"The ground truth labels:\")\n",
    "# #print(np.argmax(y_test_lib_oh, axis = 1))\n",
    "# print(\"Liberal LASSO accuracy: \")\n",
    "# #print(accuracy_score(y_test_lib_oh, lasso_lib_pred))#np.argmax(y_test_lib_oh, axis = 1), np.argmax(lasso_LIB_model.predict(X_test_lib_oh), axis=1)))\n",
    "# print(lasso_LIB_model.coef_) #feature significance\n",
    "# print()\n",
    "# print(lasso_CON_model.predict(X_test_con_oh))\n",
    "# print(\"The ground truth labels:\")\n",
    "# print(y_test_con_oh)\n",
    "lasso_CON_model.score(X_test_con_oh,y_test_con_oh)\n",
    "print(lasso_CON_model.intercept_)\n",
    "#con_preds = lasso_CON_model.predict(X_test_con_oh)\n",
    "\n",
    "\n",
    "# enc.fit_transform(y_test_con_oh)\n",
    "\n",
    "#metrics_printer(enc.inverse_transform(y_test_con_oh),enc.invrse_transform(y_test_con_oh))\n",
    "\n",
    "# for i in con_preds:\n",
    "#     print(enc.inverse_transform(i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TIP: One hot encoding does not work well with Logistic Regression; a one hot encoding will case the matrix of input data to become singular, meaning it cannot be inverted and the linear regression coefficients cannot be calculated using linear algebra. For these types of models a dummy variable encoding must be used instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So: Label encoding the data for the Logistic Regression (and the Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lib_cat = y_lib.copy()        #NOT SURE WHAT THIS STEP DOES, MAYBE IT IS REDUNDANT\n",
    "y_con_cat = y_con.copy()\n",
    "\n",
    "# y_lib_cat = y_lib_cat.astype('category')\n",
    "# y_con_cat = y_con_cat.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_lib_labelencoded = label_encoder.fit_transform(y_lib_cat)\n",
    "y_con_labelencoded = label_encoder.fit_transform(y_con_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling (only for CONSERVATIVE PREDICTION for now)\n",
    "\n",
    "https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/\n",
    "\n",
    "https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/\n",
    "\n",
    "Random oversampling involves randomly duplicating examples from the minority class and adding them to the training dataset.\n",
    "\n",
    "Examples from the training dataset are selected randomly with replacement. This means that examples from the minority class can be chosen and added to the new “more balanced” training dataset multiple times; they are selected from the original training dataset, added to the new training dataset, and then returned or “replaced” in the original dataset, allowing them to be selected again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22.1\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler \n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lib_l, X_test_lib_l, y_train_lib_l, y_test_lib_l = train_test_split(X_lib, y_lib_labelencoded, test_size=0.30, random_state=10)\n",
    "X_train_con_l, X_test_con_l, y_train_con_l, y_test_con_l = train_test_split(X_con, y_con_labelencoded, test_size=0.30, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_LIB = LogisticRegression(random_state=0)\n",
    "logistic_regression_LIB.fit(X_train_lib_l, y_train_lib_l)\n",
    "\n",
    "logistic_regression_CON = LogisticRegression(random_state=0)\n",
    "logistic_regression_CON.fit(X_train_con_l, y_train_con_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liberal LR predicts:  [0 0 0 ... 0 0 0]\n",
      "Ground truth:  [1 0 0 ... 0 0 0]\n",
      "0.8825632563256326\n",
      "Conservative LR predicts: \n",
      "Ground truth:  [1 0 0 ... 0 0 1]\n",
      "0.5908111988513999\n",
      "\n",
      "LIBERAL COEFFICIENTS\n",
      "[[ 0.49919619 -0.04080791 -0.13054757 -0.09643039 -0.14987894 -0.08033117\n",
      "  -0.15718796 -0.19202133 -0.16193753 -0.18695461]]\n",
      "\n",
      "CONSERVATIVE COEFFICIENTS\n",
      "[[-0.46179378 -0.02419632 -0.0664999   0.04237721  0.07434872 -0.01327747\n",
      "   0.09786605  0.15873358  0.05412356  0.21810127]]\n",
      "CONSEVATIVE LOGISTIC REGRESSION - BALANCED - Threshold at 8 \n",
      "Accuracy:  0.5908111988513999\n",
      "Sensitivity:  0.6391304347826087\n",
      "Specificity:  0.5433854907539118\n"
     ]
    }
   ],
   "source": [
    "LR_lib_pred = logistic_regression_LIB.predict(X_test_lib_l)\n",
    "print(\"Liberal LR predicts: \",LR_lib_pred )\n",
    "print(\"Ground truth: \", y_test_lib_l)\n",
    "\n",
    "print(accuracy_score(y_test_lib_l, LR_lib_pred))\n",
    "\n",
    "LR_con_pred = logistic_regression_CON.predict(X_test_con_l)\n",
    "print(\"Conservative LR predicts: \", )\n",
    "print(\"Ground truth: \", y_test_con_l)\n",
    "print(accuracy_score(y_test_con_l, LR_con_pred))\n",
    "print()\n",
    "print(\"LIBERAL COEFFICIENTS\")\n",
    "print(logistic_regression_LIB.coef_)\n",
    "\n",
    "print()\n",
    "print(\"CONSERVATIVE COEFFICIENTS\")\n",
    "print(logistic_regression_CON.coef_)\n",
    "\n",
    "# Liberal LR predicts:  [0 0 0 ... 0 0 0]\n",
    "# Ground truth:  [1 0 0 ... 0 0 0]\n",
    "# 0.8820682068206821\n",
    "# Conservative LR predicts: \n",
    "# Ground truth:  [0 0 0 ... 0 1 0]\n",
    "# 0.7358635863586359\n",
    "\n",
    "\n",
    "metrics_printer(y_test_con_l, LR_con_pred, f\"CONSEVATIVE LOGISTIC REGRESSION - BALANCED - Threshold at {lrthreshold} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result interpretation:\n",
    "\n",
    "LIBERAL COEFFICIENTS\n",
    "[[ 0.64696149  0.10334159  0.00508842  0.03620765 -0.00407959  0.05359682\n",
    "  -0.02097152 -0.05334792 -0.013917   -0.057601  ]]\n",
    "\n",
    "CONSERVATIVE COEFFICIENTS\n",
    "[[-0.39614516  0.027852    0.03136662  0.11140505  0.06367177 -0.00044922\n",
    "   0.11708522  0.08849489  0.14891201  0.24233131]]\n",
    "   \n",
    "The external correlations match those given at https://gosling.psy.utexas.edu/wp-content/uploads/2016/12/Sandy-et-al-JPA-2016-Brief-values-measures.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix: \n",
    "Shows that the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liberal confusion matrix: \n",
      " [[9627    0]\n",
      " [1281    0]]\n",
      "conservative confusion matrix: \n",
      " [[916 683]\n",
      " [661 955]]\n"
     ]
    }
   ],
   "source": [
    "cm_lib = metrics.confusion_matrix(y_test_lib_l, LR_lib_pred)\n",
    "print(\"liberal confusion matrix: \\n\", cm_lib)\n",
    "\n",
    "cm_con = metrics.confusion_matrix(y_test_con_l, LR_con_pred)\n",
    "print(\"conservative confusion matrix: \\n\", cm_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88476348 0.88476348 0.88476348 0.88476348 0.88476348 0.88476348\n",
      " 0.88476348 0.88476348 0.8850385  0.8850385 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_LIB_CVVVVV = LogisticRegression(random_state=0)\n",
    "\n",
    "cv_results_lib = cross_validate(logistic_regression_LIB_CVVVVV, X_lib, y_lib_labelencoded, cv=10)\n",
    "\n",
    "cv_results_con = cross_validate(logistic_regression_CON, X_con, y_con_labelencoded, cv=3)\n",
    "\n",
    "print(cv_results_lib['test_score'])\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "… there are occasions when a complete set of dummy variables is useful. For example, the splits in a tree-based model are more interpretable when the dummy variables encode all the information for that predictor. We recommend using the full set if dummy variables when working with tree-based models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of liberal Random Forest  0.5145764576457645\n",
      "Accuracy of conservative Random Forest  0.5721464465183058\n"
     ]
    }
   ],
   "source": [
    "rf_lib = RandomForestClassifier(max_depth=None, random_state=0)\n",
    "rf_lib.fit(X_train_lib_l, y_train_lib_l)\n",
    "\n",
    "rf_con = RandomForestClassifier(max_depth= None, random_state=0)\n",
    "rf_lib.fit(X_train_con_l, y_train_con_l)\n",
    "\n",
    "\n",
    "rf_lib_predicted = rf_lib.predict(X_test_lib_l)\n",
    "rf_con_predicted = rf_lib.predict(X_test_con_l)\n",
    "\n",
    "print(\"Accuracy of liberal Random Forest \", accuracy_score(y_test_lib_l,rf_lib_predicted))\n",
    "print(\"Accuracy of conservative Random Forest \", accuracy_score(y_test_con_l,rf_con_predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liberal confusion matrix: \n",
      " [[5124 4503]\n",
      " [ 792  489]]\n",
      "conservative confusion matrix: \n",
      " [[397 306]\n",
      " [290 400]]\n"
     ]
    }
   ],
   "source": [
    "rf_cm_lib = metrics.confusion_matrix(y_test_lib_l, rf_lib_predicted)\n",
    "print(\"liberal confusion matrix: \\n\", rf_cm_lib)\n",
    "\n",
    "rf_cm_con = metrics.confusion_matrix(y_test_con_l, rf_con_predicted)\n",
    "print(\"conservative confusion matrix: \\n\", rf_cm_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Conservative - BALANCED DATA - threshold at 8\n",
      "Accuracy:  0.5721464465183058\n",
      "Sensitivity:  0.5797101449275363\n",
      "Specificity:  0.5647226173541963\n"
     ]
    }
   ],
   "source": [
    "metrics_printer(y_test_con_l, rf_con_predicted, f\"Random Forest Conservative - BALANCED DATA - threshold at {lrthreshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes (ToDo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lib_gnb = GaussianNB()\n",
    "\n",
    "lib_gnb.fit(X_train_lib_l, y_train_lib_l)\n",
    "\n",
    "\n",
    "con_gnb = GaussianNB()\n",
    "\n",
    "con_gnb.fit(X_train_con_l, y_train_con_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8735790245691236\n",
      "[[9454  173]\n",
      " [1206   75]]\n",
      "9454 173 1206 75\n",
      "0.7355152181884855\n",
      "[[7963   86]\n",
      " [2799   60]]\n"
     ]
    }
   ],
   "source": [
    "lib_gnb_predicted = lib_gnb.predict(X_test_lib_l)\n",
    "gnb_cm_lib = metrics.confusion_matrix(y_test_lib_l,lib_gnb_predicted)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test_lib_l,lib_gnb_predicted).ravel()\n",
    "\n",
    "con_gnb_predicted = con_gnb.predict(X_test_con_l)\n",
    "gnb_cm_con = metrics.confusion_matrix(y_test_con_l,con_gnb_predicted)\n",
    "print(accuracy_score(y_test_lib_l,lib_gnb_predicted))\n",
    "print(gnb_cm_lib)\n",
    "print(tn, fp, fn, tp)\n",
    "print(accuracy_score(y_test_con_l,con_gnb_predicted))\n",
    "print(gnb_cm_con)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection - experiments: \n",
    "*first attempt on the conservative classifier*\n",
    "\n",
    "Liberal significant features: \n",
    "\n",
    "Conservative significant features: Conformity, Tradition, Universalism, Self direction, Stimulation, Hedonism, Achievement (power), Security\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>universalism</th>\n",
       "      <th>achievement</th>\n",
       "      <th>self_direction</th>\n",
       "      <th>stimulation</th>\n",
       "      <th>hedonism</th>\n",
       "      <th>power</th>\n",
       "      <th>security</th>\n",
       "      <th>conformity</th>\n",
       "      <th>tradition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.65</td>\n",
       "      <td>2.816667</td>\n",
       "      <td>4.316667</td>\n",
       "      <td>3.316667</td>\n",
       "      <td>3.816667</td>\n",
       "      <td>3.816667</td>\n",
       "      <td>2.316667</td>\n",
       "      <td>3.816667</td>\n",
       "      <td>4.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.70</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>4.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.35</td>\n",
       "      <td>3.516667</td>\n",
       "      <td>3.516667</td>\n",
       "      <td>3.516667</td>\n",
       "      <td>4.016667</td>\n",
       "      <td>3.016667</td>\n",
       "      <td>3.516667</td>\n",
       "      <td>2.016667</td>\n",
       "      <td>3.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.90</td>\n",
       "      <td>4.566667</td>\n",
       "      <td>4.566667</td>\n",
       "      <td>3.066667</td>\n",
       "      <td>2.566667</td>\n",
       "      <td>1.066667</td>\n",
       "      <td>4.566667</td>\n",
       "      <td>3.566667</td>\n",
       "      <td>3.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.70</td>\n",
       "      <td>3.533333</td>\n",
       "      <td>4.533333</td>\n",
       "      <td>3.533333</td>\n",
       "      <td>3.533333</td>\n",
       "      <td>2.533333</td>\n",
       "      <td>3.033333</td>\n",
       "      <td>2.033333</td>\n",
       "      <td>3.533333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   universalism  achievement  self_direction  stimulation  hedonism     power  \\\n",
       "0          3.65     2.816667        4.316667     3.316667  3.816667  3.816667   \n",
       "1          3.70     4.700000        5.200000     2.700000  3.200000  1.700000   \n",
       "2          3.35     3.516667        3.516667     3.516667  4.016667  3.016667   \n",
       "3          3.90     4.566667        4.566667     3.066667  2.566667  1.066667   \n",
       "4          4.70     3.533333        4.533333     3.533333  3.533333  2.533333   \n",
       "\n",
       "   security  conformity  tradition  \n",
       "0  2.316667    3.816667   4.316667  \n",
       "1  5.200000    1.700000   4.700000  \n",
       "2  3.516667    2.016667   3.516667  \n",
       "3  4.566667    3.566667   3.066667  \n",
       "4  3.033333    2.033333   3.533333  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_con_featureslected = X_con.copy().drop(['benevolence'], axis = 1)\n",
    "\n",
    "X_con_featureslected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_con_onehot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-493eea97b607>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_con_oh_fs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_con_oh_fs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_con_oh_fs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_con_oh_fs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_con_featureslected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_con_onehot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_con_onehot' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_con_oh_fs, X_test_con_oh_fs, y_train_con_oh_fs, y_test_con_oh_fs = train_test_split(X_con_featureslected, y_con_onehot, test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_con_gnb = GaussianNB()\n",
    "\n",
    "fs_con_gnb.fit(X_train_con_oh_fs, y_train_con_oh_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6657   34 2378   21]\n",
      "0.7346534653465346\n",
      "[0 0 0 ... 0 0 0]\n",
      "[[6657   34]\n",
      " [2378   21]]\n",
      "9035\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "fs_con_gnb_predicted = fs_con_gnb.predict(X_test_con_oh_fs)\n",
    "fs_gnb_cm_con = metrics.confusion_matrix(y_test_con_oh_fs,fs_con_gnb_predicted)\n",
    "print(metrics.confusion_matrix(y_test_con_oh_fs,fs_con_gnb_predicted).ravel())\n",
    "print(accuracy_score(y_test_con_oh_fs,fs_con_gnb_predicted))\n",
    "\n",
    "print(label_encoder.inverse_transform(fs_con_gnb_predicted))\n",
    "print(metrics.confusion_matrix(y_test_con_oh_fs,fs_con_gnb_predicted))\n",
    "\n",
    "print(list(fs_con_gnb_predicted).count(0))\n",
    "print(list(label_encoder.inverse_transform(fs_con_gnb_predicted)).count('conservative'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations: \n",
    "(with normalisations of conservatives over 7 (i.e. > 7)\n",
    "- NB using OneHot encoding and having removed Benevolence: 93% accuracy\n",
    "[   2  605]\n",
    " [   4 8479]]\n",
    " \n",
    "- NB using OneHot encoding and having removed Benevelonece & Power: 93% accuracy\n",
    "[[   0  607]\n",
    " [   2 8481]]\n",
    "\n",
    "-  NB using Label encoding and having removed Benevolence: 84.8% accuracy\n",
    "[[  10 1370]\n",
    " [   8 7702]]\n",
    " \n",
    "- NB using Label encoding and having removed Benevolence & Power: 84.8%\n",
    "[[   6 1374]\n",
    " [   3 7707]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_rf_con = RandomForestClassifier(max_depth=None, random_state=0)\n",
    "fs_rf_con.fit(X_train_con_oh_fs, y_train_con_oh_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7346534653465346\n",
      "[[6657   34]\n",
      " [2378   21]]\n"
     ]
    }
   ],
   "source": [
    "fs_rf_con_predicted = fs_con_gnb.predict(X_test_con_oh_fs)\n",
    "print(accuracy_score(y_test_con_oh_fs,fs_rf_con_predicted))\n",
    "print(metrics.confusion_matrix(y_test_con_oh_fs,fs_rf_con_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking Algorithms\n",
    "\n",
    "- Training data consists of lists of items with some partial order specified between items in each list. This order is typically induced by giving a numerical or ordinal score or a binary judgment (e.g. \"relevant\" or \"not relevant\") for each item. The ranking model purposes to rank, i.e. producing a permutation of items in new, unseen lists in a similar way to rankings in the training data.\n",
    "\n",
    "Ideas: \n",
    "    - Rank based on 'higher value = most important' (i.e. based on the assumption that conservatives have similar higher values  and similar lower values)\n",
    "    - Rank based  on ''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lib_RANK1 = X_lib.copy()\n",
    "X_con_RANK1 = X_con.copy()\n",
    "\n",
    "# X_lib_RANK1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_value (dataframe):\n",
    "    df = dataframe.copy()\n",
    "    df_comps = pd.DataFrame()\n",
    "    col_name =''\n",
    "    for column_name, data in df.iteritems():\n",
    "        for other_column_name, other_data in df.iteritems():\n",
    "            if column_name != other_column_name:\n",
    "                comp_col_name = column_name + ' < ' + other_column_name\n",
    "                df_comps[comp_col_name] = df[column_name] < df[other_column_name]\n",
    "\n",
    "    return df_comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_con_RANK = relative_value(X_con_RANK1)\n",
    "X_lib_RANK = X_con_RANK.copy()\n",
    "\n",
    "len(X_lib_RANK.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_lib = lib_dataframe.iloc[:, 2:12].copy()\n",
    "# y_lib = lib_dataframe.iloc[:,1].copy()\n",
    "# #Now the data frame for conservative prediction\n",
    "# X_con = con_dataframe.iloc[:, 2:12].copy()\n",
    "# y_con = con_dataframe.iloc[:,1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_lib_labelencoded = label_encoder.fit_transform(y_lib)\n",
    "y_con_labelencoded = label_encoder.fit_transform(y_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(sparse=False)\n",
    "y_lib_onehot = enc.fit_transform(y_lib.to_numpy().reshape(-1, 1))\n",
    "y_con_onehot = enc.fit_transform(y_con.to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_lib, X_test_lib, y_train_lib, y_test_lib = train_test_split(X_lib_RANK, y_lib_labelencoded, test_size=0.30, random_state=10)\n",
    "X_train_con, X_test_con, y_train_con, y_test_con = train_test_split(X_con_RANK, y_con_labelencoded, test_size=0.30, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2830"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y_test_con).count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_printer (ground_truth, model_predicted, classification_target = None):\n",
    "    \"\"\"Return sensitivity,specificity,accuracy & if given classification target\"\"\"\n",
    "    if classification_target != None: \n",
    "        print(classification_target)\n",
    "    tnegative, fpositive, fnegative, tpositive = metrics.confusion_matrix(ground_truth,model_predicted).ravel()\n",
    "    print(\"Accuracy: \", accuracy_score(ground_truth,model_predicted))\n",
    "    print(\"Sensitivity: \", sensitivity(tpositive,fnegative))\n",
    "    print(\"Specificity: \", specificity(tnegative,fpositive))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_gnb_RANK = GaussianNB()\n",
    "con_gnb_RANK.fit(X_train_con, y_train_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5607808340727596\n",
      "Sensitivity:  0.4467023172905526\n",
      "Specificity:  0.673851590106007\n"
     ]
    }
   ],
   "source": [
    "con_RANK_predicted = con_gnb_RANK.predict(X_test_con)\n",
    "# print(type(con_RANK_predicted))\n",
    "# print(accuracy_score(y_test_con,con_RANK_predicted))\n",
    "# tnegative, fpositive, fnegative, tpositive = metrics.confusion_matrix(y_test_con,con_RANK_predicted).ravel()\n",
    "# print(\"tn\",tnegative, \"fp\",fpositive, \"fn\",fnegative,\"tp\", tpositive)\n",
    "# print(metrics.confusion_matrix(y_test_con,con_RANK_predicted))\n",
    "\n",
    "# sensitivity(tpositive,fnegative)\n",
    "# specificity(tnegative,fpositive)\n",
    "\n",
    "# (TP / (TP + FN))\n",
    "# (TN / (TN + FP))\n",
    "\n",
    "metrics_printer(y_test_con,con_RANK_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"LIBERAL NB RANKED\"\"\"\n",
    "\n",
    "lib_gnb_RANK = GaussianNB()\n",
    "#X_train_lib, X_test_lib, y_train_lib, y_test_lib\n",
    "lib_gnb_RANK.fit(X_train_lib, y_train_lib)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_rank_predicted = lib_gnb_RANK.predict(X_test_lib)\n",
    "metrics_printer(y_test_lib,lib_rank_predicted,\"Liberal Ranked NB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lib_rank_predicted)\n",
    "print(label_encoder.inverse_transform(lib_rank_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_con_RANK = RandomForestClassifier(max_depth= None, random_state=0)\n",
    "rf_con_RANK.fit(X_train_con, y_train_con)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of conservative Random Forest  0.5506654835847382\n",
      "[[1570 1260]\n",
      " [1272 1533]]\n",
      "Accuracy:  0.5506654835847382\n",
      "Sensitivity:  0.546524064171123\n",
      "Specificity:  0.5547703180212014\n"
     ]
    }
   ],
   "source": [
    "rf_con_RANK_predicted = rf_con_RANK.predict(X_test_con)\n",
    "\n",
    "\n",
    "print(\"Accuracy of conservative Random Forest \", accuracy_score(y_test_con,rf_con_RANK_predicted))\n",
    "\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test_con,rf_con_RANK_predicted).ravel()\n",
    "\n",
    "print(metrics.confusion_matrix(y_test_con,rf_con_RANK_predicted))\n",
    "\n",
    "# print(\"tn\",tn, \"fp\",fp, \"fn\",fn,\"tp\", tp)\n",
    "\n",
    "metrics_printer(y_test_con,rf_con_RANK_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conservative RF\n",
      "Accuracy:  0.5506654835847382\n",
      "Sensitivity:  0.546524064171123\n",
      "Specificity:  0.5547703180212014\n"
     ]
    }
   ],
   "source": [
    "metrics_printer(y_test_con,rf_con_RANK_predicted,\"Conservative RF\")\n",
    "# print(rf_con_RANK_predicted)\n",
    "# print(label_encoder.inverse_transform(rf_con_RANK_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest:\n",
    "_Normalistion point @ 8_\n",
    "Accuracy of conservative Random Forest  0.9242757609094243\n",
    "\n",
    "Sensitivity = 0.9872486512996567\n",
    "Specificity = 0.023842917251051893\n",
    "\n",
    "[   17   696]\n",
    "[  130 10065]\n",
    "\n",
    "---------------------------------------------------------------\n",
    " \n",
    "_Normalisation point @ 7_\n",
    "Accuracy of conservative Random Forest  0.8423175650898423\n",
    "\n",
    "Sensitivity = 0.9872803708095289\n",
    "Specificity = 0.04595879556259905\n",
    "\n",
    "[  29 1602]\n",
    "[ 118 9159]\n",
    "\n",
    "---------------------------------------------------------------\n",
    " \n",
    "_Normalisatin point @ 6\n",
    "Accuracy of conservative Random Forest  0.7326732673267327\n",
    "\n",
    "Sensitivity = 0.9873276183376817\n",
    "Specificity = 0.015739769150052464\n",
    "\n",
    "[  45 2814]\n",
    "[ 102 7947]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-e34a0a8b260f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mAccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mTN\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mTN\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mSensitivity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTP\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mSpecificity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTN\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTN\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TP' is not defined"
     ]
    }
   ],
   "source": [
    "Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "Sensitivity = TP / (TP + FN)\n",
    "Specificity = TN / (TN + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity(TP, FN):\n",
    "    sensitivity = (TP / (TP + FN))\n",
    "   # print(sensitivity)\n",
    "    return sensitivity\n",
    "\n",
    "def specificity (TN, FP):\n",
    "    specificity = (TN / (TN + FP))\n",
    "   # print(specificity)\n",
    "    return specificity\n",
    "\n",
    "# print(sensitivity(tp,fn))\n",
    "# print(specificity( tn,fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
