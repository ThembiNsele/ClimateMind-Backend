{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4033\n",
      "0    0\n",
      "1    1\n",
      "2    5\n",
      "3    0\n",
      "4    5\n",
      "Name: lrscale, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv(\"pvq21_REVERSED_CENTRED.csv\", sep=',')\n",
    "lib_dataframe = data.copy()\n",
    "con_dataframe = data.copy()\n",
    "\n",
    "ub_dataframe = data.copy()\n",
    "((ub_dataframe[ub_dataframe['lrscale'] > 7].shape[0])/ ub_dataframe.shape[0]) *100\n",
    "\n",
    "\n",
    "lrscale_balanced = ub_dataframe['lrscale']\n",
    "\n",
    "print(ub_dataframe[ub_dataframe['lrscale'] == 7].shape[0])\n",
    "\n",
    "lrscale_balanced.hist(bins=11, figsize=[14,6])\n",
    "\n",
    "print(ub_dataframe['lrscale'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing the data\n",
    "Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Randomise dataframe\n",
    "2. counter variable = 0\n",
    "3. Go through the dataframe       *Or actually just pick all instances over this lr threshold* \n",
    "    3.1 For ever lrscore > threshold\n",
    "        3.2 Add to a new dataframe\n",
    "        3.3 counter ++ \n",
    "     \n",
    "4. While the new (balancer) dataframe is <= to the 50% of length of the full dataframe \n",
    "\n",
    "    4.1 Copy to itself\n",
    "    \n",
    "    \n",
    "5. Attach balancer dataframe to the previous data frame\n",
    "6. Return new dataframe \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36360\n",
      "(36360, 13)\n"
     ]
    }
   ],
   "source": [
    "#Some exploration:\n",
    "print(len(ub_dataframe))\n",
    "print(ub_dataframe.shape)\n",
    "\n",
    "\n",
    "def balance_samples(unbalanced_dataframe, lrthreshold):\n",
    "    \"\"\"Return a balanced dataframe i.e. consisting at 50% of the examples/cases above the lrthreshold (not inclusive)\"\"\"\n",
    "    balancer_dataframe = pd.DataFrame()\n",
    "\n",
    "    balancer_dataframe = unbalanced_dataframe[unbalanced_dataframe['lrscale'] > lrthreshold].copy()\n",
    "\n",
    "    #Calculate the 50% \n",
    "    half_value = int(len(unbalanced_dataframe)/2)\n",
    "\n",
    "\n",
    "    #The difference to getting a number of samples equal to 50 % of the original dataset\n",
    "   # dif_half = half_value - len(balancer_dataframe)\n",
    "\n",
    "    copy_balancer_dataframe = balancer_dataframe.sample(n = half_value, replace=True).reset_index(drop=True)\n",
    "    \n",
    "    balancer_dataframe = pd.concat([balancer_dataframe,copy_balancer_dataframe], axis=0)\n",
    "\n",
    "    balanced_df = pd.concat([unbalanced_dataframe,balancer_dataframe], axis=0)\n",
    "\n",
    "    balanced_df = balanced_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    return balanced_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersample(unbalanced_dataframe, lrthreshold, skew_distribution = 0.5):\n",
    "    \"\"\"Return a balanced dataframe i.e. consisting at 50% of the examples/cases above the lrthreshold (inclusive)\"\"\"\n",
    "    balancer_dataframe = unbalanced_dataframe.copy()\n",
    "    #balancer_data\n",
    "    minority_df = balancer_dataframe[balancer_dataframe['lrscale'] > lrthreshold]\n",
    "    minority_count = minority_df.shape[0]\n",
    "\n",
    "    print(\"minority_count\", minority_count)\n",
    "\n",
    "    print(\"TESTHOWMANY??\", balancer_dataframe[balancer_dataframe['lrscale'] <= lrthreshold].shape[0])\n",
    "    #pick and remove a random sample of instances under the set threshold\n",
    "    majority_balancer = balancer_dataframe[balancer_dataframe['lrscale'] <= lrthreshold].sample(n=minority_count, replace = False)\n",
    "    \n",
    "    balanced_df = pd.concat([minority_df,majority_balancer],axis=0)\n",
    "    balanced_df = balanced_df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "#     print(\"majority balancer\", majority_balancer.shape[0])\n",
    "#     print(\"minority df\", minority_df.shape[0])\n",
    "#     print(\"balanced df\", balanced_df.shape[0])\n",
    "\n",
    "    \n",
    "    return balanced_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_count 9391\n",
      "TESTHOWMANY?? 26969\n"
     ]
    }
   ],
   "source": [
    "lrthreshold = 6\n",
    "# print(con_dataframe.head())\n",
    "balanced_dataframe = undersample(ub_dataframe, lrthreshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_count 9391\n",
      "TESTHOWMANY?? 26969\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "undersampled_dataframe = undersample(ub_dataframe,lrthreshold)\n",
    "\n",
    "\n",
    "\n",
    "print(type(balanced_dataframe))\n",
    "print(type(undersampled_dataframe))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18782, 13)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576000x72000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(undersampled_dataframe.shape)\n",
    "\n",
    "# balanced_dataframe[balanced_dataframe['lrscale'] > 7].shape[0]\n",
    "# lrscale_balanced = undersampled_dataframe['lrscale']\n",
    "# lrscale_balanced.hist(bins=10, figsize=[14,6])\n",
    "\n",
    "def hist_plotter(dataframe,threshold):\n",
    "    lrscale_balanced = dataframe['lrscale']\n",
    "    n,bins,patches = plt.hist(lrscale_balanced, bins=[0, 1, 2, 3, 4, 5, 6,7,8,9,10], color='b')\n",
    "    plt.title(f\"Distribution on threshold > {threshold}\") \n",
    "    plt.figure(figsize=(8000,1000))\n",
    "    \n",
    "    for patch_num in range(threshold, 10):\n",
    "        patches[patch_num].set_fc('g')\n",
    "\n",
    "hist_plotter(undersampled_dataframe,lrthreshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percenatge of scores over 6  50.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"The percenatge of scores over {lrthreshold} \",((undersampled_dataframe[undersampled_dataframe['lrscale'] > lrthreshold].shape[0]) / undersampled_dataframe.shape[0])*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  lrscale  universalism  achievement  benevolence  \\\n",
      "0       27605        7          4.15     3.483333     3.983333   \n",
      "1       22651        5          4.75     1.750000     4.750000   \n",
      "2       17011        7          3.95     2.950000     3.950000   \n",
      "3        3770        5          4.15     4.150000     4.150000   \n",
      "4        4661        6          3.85     3.516667     4.516667   \n",
      "\n",
      "   self_direction  stimulation  hedonism     power  security  conformity  \\\n",
      "0        2.483333     2.483333  2.983333  3.483333  3.483333    4.483333   \n",
      "1        3.250000     1.750000  1.250000  2.250000  5.750000    4.750000   \n",
      "2        3.450000     4.450000  4.450000  1.950000  3.450000    2.450000   \n",
      "3        2.650000     2.150000  1.150000  4.150000  4.150000    4.150000   \n",
      "4        4.016667     2.516667  4.516667  3.516667  3.516667    3.016667   \n",
      "\n",
      "   tradition     p_avg  \n",
      "0   3.983333  4.016667  \n",
      "1   4.750000  3.750000  \n",
      "2   3.950000  4.550000  \n",
      "3   4.150000  4.350000  \n",
      "4   2.016667  4.983333  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(balanced_dataframe.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the (almost) balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_dataframe = undersampled_dataframe.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18782, 13)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_dataframe.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bin the data for each dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_lib (value):\n",
    "\n",
    "        if value < 3:\n",
    "            return 1#\"liberal\" #liberal\n",
    "        else:\n",
    "            return 0#\"moderate\" #moderate\n",
    "\n",
    "def normalise_con (value):\n",
    "        \n",
    "        if value > lrthreshold:\n",
    "            return 1#\"conservative\" #conservative\n",
    "        else:\n",
    "            return 0#\"moderate\" #moderate\n",
    "        \n",
    "\n",
    "lib_dataframe['lrscale'] = lib_dataframe['lrscale'].apply(normalise_lib)\n",
    "con_dataframe['lrscale'] = con_dataframe['lrscale'].apply(normalise_con)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    0\n",
      "4    1\n",
      "Name: lrscale, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_lib = lib_dataframe.iloc[:, 2:12].copy()\n",
    "y_lib = lib_dataframe.iloc[:,1].copy()\n",
    "#Now the data frame for conservative prediction\n",
    "X_con = con_dataframe.iloc[:, 2:12].copy()\n",
    "y_con = con_dataframe.iloc[:,1].copy()\n",
    "\n",
    "print(y_con.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9391\n",
      "9391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list(y_con).count(1))\n",
    "print(list(y_con).count(0))\n",
    "\n",
    "con_lib_ratio = (list(y_con).count(1)/(list(y_con).count(0) + list(y_con).count(1)) * 100)\n",
    "con_lib_ratio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(sparse=False)\n",
    "y_lib_onehot = enc.fit_transform(y_lib.to_numpy().reshape(-1, 1))\n",
    "y_con_onehot = enc.fit_transform(y_con.to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Encoding instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_lib_onehot = label_encoder.fit_transform(y_lib.copy())\n",
    "y_con_onehot = label_encoder.fit_transform(y_con.copy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lib_oh, X_test_lib_oh, y_train_lib_oh, y_test_lib_oh = train_test_split(X_lib, y_lib_onehot, test_size=0.25, random_state=10)\n",
    "X_train_con_oh, X_test_con_oh, y_train_con_oh, y_test_con_oh = train_test_split(X_con, y_con_onehot, test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call this function to perform cross validation to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(model):\n",
    "    #return scores\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "      normalize=False, positive=False, precompute=False, random_state=None,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class Lasso():\n",
    "lasso_LIB_model = Lasso(alpha=1.0)\n",
    "#fitting the liberal model\n",
    "lasso_LIB_model.fit(X_train_lib_oh,y_train_lib_oh)\n",
    "\n",
    "lasso_CON_model = Lasso(alpha=1.0)\n",
    "lasso_CON_model.fit(X_train_con_oh,y_train_con_oh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49943206 0.50056794]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:434: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lasso_lib_pred = lasso_LIB_model.predict(X_test_lib_oh)\n",
    "# print(lasso_lib_pred)\n",
    "\n",
    "#enc.inverse_transform([np.argmax(lasso_lib_pred[0, :])])\n",
    "# #print(lasso_lib_pred[0, :])\n",
    "# print(\"The ground truth labels:\")\n",
    "# #print(np.argmax(y_test_lib_oh, axis = 1))\n",
    "# print(\"Liberal LASSO accuracy: \")\n",
    "# #print(accuracy_score(y_test_lib_oh, lasso_lib_pred))#np.argmax(y_test_lib_oh, axis = 1), np.argmax(lasso_LIB_model.predict(X_test_lib_oh), axis=1)))\n",
    "# print(lasso_LIB_model.coef_) #feature significance\n",
    "# print()\n",
    "# print(lasso_CON_model.predict(X_test_con_oh))\n",
    "# print(\"The ground truth labels:\")\n",
    "# print(y_test_con_oh)\n",
    "lasso_CON_model.score(X_test_con_oh,y_test_con_oh)\n",
    "print(lasso_CON_model.intercept_)\n",
    "#con_preds = lasso_CON_model.predict(X_test_con_oh)\n",
    "\n",
    "\n",
    "# enc.fit_transform(y_test_con_oh)\n",
    "\n",
    "#metrics_printer(enc.inverse_transform(y_test_con_oh),enc.invrse_transform(y_test_con_oh))\n",
    "\n",
    "# for i in con_preds:\n",
    "#     print(enc.inverse_transform(i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TIP: One hot encoding does not work well with Logistic Regression; a one hot encoding will case the matrix of input data to become singular, meaning it cannot be inverted and the linear regression coefficients cannot be calculated using linear algebra. For these types of models a dummy variable encoding must be used instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So: Label encoding the data for the Logistic Regression (and the Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lib_cat = y_lib.copy()        #NOT SURE WHAT THIS STEP DOES, MAYBE IT IS REDUNDANT\n",
    "y_con_cat = y_con.copy()\n",
    "\n",
    "# y_lib_cat = y_lib_cat.astype('category')\n",
    "# y_con_cat = y_con_cat.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_lib_labelencoded = label_encoder.fit_transform(y_lib_cat)\n",
    "y_con_labelencoded = label_encoder.fit_transform(y_con_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling (only for CONSERVATIVE PREDICTION for now)\n",
    "\n",
    "https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/\n",
    "\n",
    "https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/\n",
    "\n",
    "Random oversampling involves randomly duplicating examples from the minority class and adding them to the training dataset.\n",
    "\n",
    "Examples from the training dataset are selected randomly with replacement. This means that examples from the minority class can be chosen and added to the new “more balanced” training dataset multiple times; they are selected from the original training dataset, added to the new training dataset, and then returned or “replaced” in the original dataset, allowing them to be selected again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22.1\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler \n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lib_l, X_test_lib_l, y_train_lib_l, y_test_lib_l = train_test_split(X_lib, y_lib_labelencoded, test_size=0.30, random_state=10)\n",
    "X_train_con_l, X_test_con_l, y_train_con_l, y_test_con_l = train_test_split(X_con, y_con_labelencoded, test_size=0.30, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_LIB = LogisticRegression(random_state=0)\n",
    "logistic_regression_LIB.fit(X_train_lib_l, y_train_lib_l)\n",
    "\n",
    "logistic_regression_CON = LogisticRegression(random_state=0)\n",
    "logistic_regression_CON.fit(X_train_con_l, y_train_con_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liberal LR predicts:  [0 0 0 ... 0 0 0]\n",
      "Ground truth:  [1 0 0 ... 0 0 0]\n",
      "0.8825632563256326\n",
      "Conservative LR predicts: \n",
      "Ground truth:  [1 0 0 ... 0 0 1]\n",
      "0.5908111988513999\n",
      "\n",
      "LIBERAL COEFFICIENTS\n",
      "[[ 0.49919619 -0.04080791 -0.13054757 -0.09643039 -0.14987894 -0.08033117\n",
      "  -0.15718796 -0.19202133 -0.16193753 -0.18695461]]\n",
      "\n",
      "CONSERVATIVE COEFFICIENTS\n",
      "[[-0.46179378 -0.02419632 -0.0664999   0.04237721  0.07434872 -0.01327747\n",
      "   0.09786605  0.15873358  0.05412356  0.21810127]]\n",
      "CONSEVATIVE LOGISTIC REGRESSION - BALANCED - Threshold at 8 \n",
      "Accuracy:  0.5908111988513999\n",
      "Sensitivity:  0.6391304347826087\n",
      "Specificity:  0.5433854907539118\n"
     ]
    }
   ],
   "source": [
    "LR_lib_pred = logistic_regression_LIB.predict(X_test_lib_l)\n",
    "print(\"Liberal LR predicts: \",LR_lib_pred )\n",
    "print(\"Ground truth: \", y_test_lib_l)\n",
    "\n",
    "print(accuracy_score(y_test_lib_l, LR_lib_pred))\n",
    "\n",
    "LR_con_pred = logistic_regression_CON.predict(X_test_con_l)\n",
    "print(\"Conservative LR predicts: \", )\n",
    "print(\"Ground truth: \", y_test_con_l)\n",
    "print(accuracy_score(y_test_con_l, LR_con_pred))\n",
    "print()\n",
    "print(\"LIBERAL COEFFICIENTS\")\n",
    "print(logistic_regression_LIB.coef_)\n",
    "\n",
    "print()\n",
    "print(\"CONSERVATIVE COEFFICIENTS\")\n",
    "print(logistic_regression_CON.coef_)\n",
    "\n",
    "# Liberal LR predicts:  [0 0 0 ... 0 0 0]\n",
    "# Ground truth:  [1 0 0 ... 0 0 0]\n",
    "# 0.8820682068206821\n",
    "# Conservative LR predicts: \n",
    "# Ground truth:  [0 0 0 ... 0 1 0]\n",
    "# 0.7358635863586359\n",
    "\n",
    "\n",
    "metrics_printer(y_test_con_l, LR_con_pred, f\"CONSEVATIVE LOGISTIC REGRESSION - BALANCED - Threshold at {lrthreshold} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result interpretation:\n",
    "\n",
    "LIBERAL COEFFICIENTS\n",
    "[[ 0.64696149  0.10334159  0.00508842  0.03620765 -0.00407959  0.05359682\n",
    "  -0.02097152 -0.05334792 -0.013917   -0.057601  ]]\n",
    "\n",
    "CONSERVATIVE COEFFICIENTS\n",
    "[[-0.39614516  0.027852    0.03136662  0.11140505  0.06367177 -0.00044922\n",
    "   0.11708522  0.08849489  0.14891201  0.24233131]]\n",
    "   \n",
    "The external correlations match those given at https://gosling.psy.utexas.edu/wp-content/uploads/2016/12/Sandy-et-al-JPA-2016-Brief-values-measures.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix: \n",
    "Shows that the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liberal confusion matrix: \n",
      " [[9627    0]\n",
      " [1281    0]]\n",
      "conservative confusion matrix: \n",
      " [[916 683]\n",
      " [661 955]]\n"
     ]
    }
   ],
   "source": [
    "cm_lib = metrics.confusion_matrix(y_test_lib_l, LR_lib_pred)\n",
    "print(\"liberal confusion matrix: \\n\", cm_lib)\n",
    "\n",
    "cm_con = metrics.confusion_matrix(y_test_con_l, LR_con_pred)\n",
    "print(\"conservative confusion matrix: \\n\", cm_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88476348 0.88476348 0.88476348 0.88476348 0.88476348 0.88476348\n",
      " 0.88476348 0.88476348 0.8850385  0.8850385 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_LIB_CVVVVV = LogisticRegression(random_state=0)\n",
    "\n",
    "cv_results_lib = cross_validate(logistic_regression_LIB_CVVVVV, X_lib, y_lib_labelencoded, cv=10)\n",
    "\n",
    "cv_results_con = cross_validate(logistic_regression_CON, X_con, y_con_labelencoded, cv=3)\n",
    "\n",
    "print(cv_results_lib['test_score'])\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "… there are occasions when a complete set of dummy variables is useful. For example, the splits in a tree-based model are more interpretable when the dummy variables encode all the information for that predictor. We recommend using the full set if dummy variables when working with tree-based models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of liberal Random Forest  0.5145764576457645\n",
      "Accuracy of conservative Random Forest  0.5721464465183058\n"
     ]
    }
   ],
   "source": [
    "rf_lib = RandomForestClassifier(max_depth=None, random_state=0)\n",
    "rf_lib.fit(X_train_lib_l, y_train_lib_l)\n",
    "\n",
    "rf_con = RandomForestClassifier(max_depth= None, random_state=0)\n",
    "rf_lib.fit(X_train_con_l, y_train_con_l)\n",
    "\n",
    "\n",
    "rf_lib_predicted = rf_lib.predict(X_test_lib_l)\n",
    "rf_con_predicted = rf_lib.predict(X_test_con_l)\n",
    "\n",
    "print(\"Accuracy of liberal Random Forest \", accuracy_score(y_test_lib_l,rf_lib_predicted))\n",
    "print(\"Accuracy of conservative Random Forest \", accuracy_score(y_test_con_l,rf_con_predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liberal confusion matrix: \n",
      " [[5124 4503]\n",
      " [ 792  489]]\n",
      "conservative confusion matrix: \n",
      " [[397 306]\n",
      " [290 400]]\n"
     ]
    }
   ],
   "source": [
    "rf_cm_lib = metrics.confusion_matrix(y_test_lib_l, rf_lib_predicted)\n",
    "print(\"liberal confusion matrix: \\n\", rf_cm_lib)\n",
    "\n",
    "rf_cm_con = metrics.confusion_matrix(y_test_con_l, rf_con_predicted)\n",
    "print(\"conservative confusion matrix: \\n\", rf_cm_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Conservative - BALANCED DATA - threshold at 8\n",
      "Accuracy:  0.5721464465183058\n",
      "Sensitivity:  0.5797101449275363\n",
      "Specificity:  0.5647226173541963\n"
     ]
    }
   ],
   "source": [
    "metrics_printer(y_test_con_l, rf_con_predicted, f\"Random Forest Conservative - BALANCED DATA - threshold at {lrthreshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes (ToDo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lib_gnb = GaussianNB()\n",
    "\n",
    "lib_gnb.fit(X_train_lib_l, y_train_lib_l)\n",
    "\n",
    "\n",
    "con_gnb = GaussianNB()\n",
    "\n",
    "con_gnb.fit(X_train_con_l, y_train_con_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8735790245691236\n",
      "[[9454  173]\n",
      " [1206   75]]\n",
      "9454 173 1206 75\n",
      "0.7355152181884855\n",
      "[[7963   86]\n",
      " [2799   60]]\n"
     ]
    }
   ],
   "source": [
    "lib_gnb_predicted = lib_gnb.predict(X_test_lib_l)\n",
    "gnb_cm_lib = metrics.confusion_matrix(y_test_lib_l,lib_gnb_predicted)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test_lib_l,lib_gnb_predicted).ravel()\n",
    "\n",
    "con_gnb_predicted = con_gnb.predict(X_test_con_l)\n",
    "gnb_cm_con = metrics.confusion_matrix(y_test_con_l,con_gnb_predicted)\n",
    "print(accuracy_score(y_test_lib_l,lib_gnb_predicted))\n",
    "print(gnb_cm_lib)\n",
    "print(tn, fp, fn, tp)\n",
    "print(accuracy_score(y_test_con_l,con_gnb_predicted))\n",
    "print(gnb_cm_con)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection - experiments: \n",
    "*first attempt on the conservative classifier*\n",
    "\n",
    "Liberal significant features: \n",
    "\n",
    "Conservative significant features: Conformity, Tradition, Universalism, Self direction, Stimulation, Hedonism, Achievement (power), Security\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>universalism</th>\n",
       "      <th>achievement</th>\n",
       "      <th>self_direction</th>\n",
       "      <th>stimulation</th>\n",
       "      <th>hedonism</th>\n",
       "      <th>power</th>\n",
       "      <th>security</th>\n",
       "      <th>conformity</th>\n",
       "      <th>tradition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.65</td>\n",
       "      <td>2.816667</td>\n",
       "      <td>4.316667</td>\n",
       "      <td>3.316667</td>\n",
       "      <td>3.816667</td>\n",
       "      <td>3.816667</td>\n",
       "      <td>2.316667</td>\n",
       "      <td>3.816667</td>\n",
       "      <td>4.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.70</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>4.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.35</td>\n",
       "      <td>3.516667</td>\n",
       "      <td>3.516667</td>\n",
       "      <td>3.516667</td>\n",
       "      <td>4.016667</td>\n",
       "      <td>3.016667</td>\n",
       "      <td>3.516667</td>\n",
       "      <td>2.016667</td>\n",
       "      <td>3.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.90</td>\n",
       "      <td>4.566667</td>\n",
       "      <td>4.566667</td>\n",
       "      <td>3.066667</td>\n",
       "      <td>2.566667</td>\n",
       "      <td>1.066667</td>\n",
       "      <td>4.566667</td>\n",
       "      <td>3.566667</td>\n",
       "      <td>3.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.70</td>\n",
       "      <td>3.533333</td>\n",
       "      <td>4.533333</td>\n",
       "      <td>3.533333</td>\n",
       "      <td>3.533333</td>\n",
       "      <td>2.533333</td>\n",
       "      <td>3.033333</td>\n",
       "      <td>2.033333</td>\n",
       "      <td>3.533333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   universalism  achievement  self_direction  stimulation  hedonism     power  \\\n",
       "0          3.65     2.816667        4.316667     3.316667  3.816667  3.816667   \n",
       "1          3.70     4.700000        5.200000     2.700000  3.200000  1.700000   \n",
       "2          3.35     3.516667        3.516667     3.516667  4.016667  3.016667   \n",
       "3          3.90     4.566667        4.566667     3.066667  2.566667  1.066667   \n",
       "4          4.70     3.533333        4.533333     3.533333  3.533333  2.533333   \n",
       "\n",
       "   security  conformity  tradition  \n",
       "0  2.316667    3.816667   4.316667  \n",
       "1  5.200000    1.700000   4.700000  \n",
       "2  3.516667    2.016667   3.516667  \n",
       "3  4.566667    3.566667   3.066667  \n",
       "4  3.033333    2.033333   3.533333  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_con_featureslected = X_con.copy().drop(['benevolence'], axis = 1)\n",
    "\n",
    "X_con_featureslected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_con_onehot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-493eea97b607>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_con_oh_fs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_con_oh_fs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_con_oh_fs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_con_oh_fs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_con_featureslected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_con_onehot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_con_onehot' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_con_oh_fs, X_test_con_oh_fs, y_train_con_oh_fs, y_test_con_oh_fs = train_test_split(X_con_featureslected, y_con_onehot, test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_con_gnb = GaussianNB()\n",
    "\n",
    "fs_con_gnb.fit(X_train_con_oh_fs, y_train_con_oh_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6657   34 2378   21]\n",
      "0.7346534653465346\n",
      "[0 0 0 ... 0 0 0]\n",
      "[[6657   34]\n",
      " [2378   21]]\n",
      "9035\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "fs_con_gnb_predicted = fs_con_gnb.predict(X_test_con_oh_fs)\n",
    "fs_gnb_cm_con = metrics.confusion_matrix(y_test_con_oh_fs,fs_con_gnb_predicted)\n",
    "print(metrics.confusion_matrix(y_test_con_oh_fs,fs_con_gnb_predicted).ravel())\n",
    "print(accuracy_score(y_test_con_oh_fs,fs_con_gnb_predicted))\n",
    "\n",
    "print(label_encoder.inverse_transform(fs_con_gnb_predicted))\n",
    "print(metrics.confusion_matrix(y_test_con_oh_fs,fs_con_gnb_predicted))\n",
    "\n",
    "print(list(fs_con_gnb_predicted).count(0))\n",
    "print(list(label_encoder.inverse_transform(fs_con_gnb_predicted)).count('conservative'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations: \n",
    "(with normalisations of conservatives over 7 (i.e. > 7)\n",
    "- NB using OneHot encoding and having removed Benevolence: 93% accuracy\n",
    "[   2  605]\n",
    " [   4 8479]]\n",
    " \n",
    "- NB using OneHot encoding and having removed Benevelonece & Power: 93% accuracy\n",
    "[[   0  607]\n",
    " [   2 8481]]\n",
    "\n",
    "-  NB using Label encoding and having removed Benevolence: 84.8% accuracy\n",
    "[[  10 1370]\n",
    " [   8 7702]]\n",
    " \n",
    "- NB using Label encoding and having removed Benevolence & Power: 84.8%\n",
    "[[   6 1374]\n",
    " [   3 7707]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_rf_con = RandomForestClassifier(max_depth=None, random_state=0)\n",
    "fs_rf_con.fit(X_train_con_oh_fs, y_train_con_oh_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7346534653465346\n",
      "[[6657   34]\n",
      " [2378   21]]\n"
     ]
    }
   ],
   "source": [
    "fs_rf_con_predicted = fs_con_gnb.predict(X_test_con_oh_fs)\n",
    "print(accuracy_score(y_test_con_oh_fs,fs_rf_con_predicted))\n",
    "print(metrics.confusion_matrix(y_test_con_oh_fs,fs_rf_con_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking Algorithms\n",
    "\n",
    "- Training data consists of lists of items with some partial order specified between items in each list. This order is typically induced by giving a numerical or ordinal score or a binary judgment (e.g. \"relevant\" or \"not relevant\") for each item. The ranking model purposes to rank, i.e. producing a permutation of items in new, unseen lists in a similar way to rankings in the training data.\n",
    "\n",
    "Ideas: \n",
    "    - Rank based on 'higher value = most important' (i.e. based on the assumption that conservatives have similar higher values  and similar lower values)\n",
    "    - Rank based  on ''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lib_RANK1 = X_lib.copy()\n",
    "X_con_RANK1 = X_con.copy()\n",
    "\n",
    "# X_lib_RANK1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_value (dataframe):\n",
    "    df = dataframe.copy()\n",
    "    df_comps = pd.DataFrame()\n",
    "    col_name =''\n",
    "    for column_name, data in df.iteritems():\n",
    "        for other_column_name, other_data in df.iteritems():\n",
    "            if column_name != other_column_name:\n",
    "                comp_col_name = column_name + ' < ' + other_column_name\n",
    "                df_comps[comp_col_name] = df[column_name] < df[other_column_name]\n",
    "\n",
    "    return df_comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_con_RANK = relative_value(X_con_RANK1)\n",
    "X_lib_RANK = X_con_RANK.copy()\n",
    "\n",
    "len(X_lib_RANK.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_lib = lib_dataframe.iloc[:, 2:12].copy()\n",
    "# y_lib = lib_dataframe.iloc[:,1].copy()\n",
    "# #Now the data frame for conservative prediction\n",
    "# X_con = con_dataframe.iloc[:, 2:12].copy()\n",
    "# y_con = con_dataframe.iloc[:,1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_lib_labelencoded = label_encoder.fit_transform(y_lib)\n",
    "y_con_labelencoded = label_encoder.fit_transform(y_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(sparse=False)\n",
    "y_lib_onehot = enc.fit_transform(y_lib.to_numpy().reshape(-1, 1))\n",
    "y_con_onehot = enc.fit_transform(y_con.to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_lib, X_test_lib, y_train_lib, y_test_lib = train_test_split(X_lib_RANK, y_lib_labelencoded, test_size=0.30, random_state=10)\n",
    "X_train_con, X_test_con, y_train_con, y_test_con = train_test_split(X_con_RANK, y_con_labelencoded, test_size=0.30, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2830"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y_test_con).count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_printer (ground_truth, model_predicted, classification_target = None):\n",
    "    \"\"\"Return sensitivity,specificity,accuracy & if given classification target\"\"\"\n",
    "    if classification_target != None: \n",
    "        print(classification_target)\n",
    "    tnegative, fpositive, fnegative, tpositive = metrics.confusion_matrix(ground_truth,model_predicted).ravel()\n",
    "    print(\"Accuracy: \", accuracy_score(ground_truth,model_predicted))\n",
    "    print(\"Sensitivity: \", sensitivity(tpositive,fnegative))\n",
    "    print(\"Specificity: \", specificity(tnegative,fpositive))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_gnb_RANK = GaussianNB()\n",
    "con_gnb_RANK.fit(X_train_con, y_train_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5607808340727596\n",
      "Sensitivity:  0.4467023172905526\n",
      "Specificity:  0.673851590106007\n"
     ]
    }
   ],
   "source": [
    "con_RANK_predicted = con_gnb_RANK.predict(X_test_con)\n",
    "# print(type(con_RANK_predicted))\n",
    "# print(accuracy_score(y_test_con,con_RANK_predicted))\n",
    "# tnegative, fpositive, fnegative, tpositive = metrics.confusion_matrix(y_test_con,con_RANK_predicted).ravel()\n",
    "# print(\"tn\",tnegative, \"fp\",fpositive, \"fn\",fnegative,\"tp\", tpositive)\n",
    "# print(metrics.confusion_matrix(y_test_con,con_RANK_predicted))\n",
    "\n",
    "# sensitivity(tpositive,fnegative)\n",
    "# specificity(tnegative,fpositive)\n",
    "\n",
    "# (TP / (TP + FN))\n",
    "# (TN / (TN + FP))\n",
    "\n",
    "metrics_printer(y_test_con,con_RANK_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"LIBERAL NB RANKED\"\"\"\n",
    "\n",
    "lib_gnb_RANK = GaussianNB()\n",
    "#X_train_lib, X_test_lib, y_train_lib, y_test_lib\n",
    "lib_gnb_RANK.fit(X_train_lib, y_train_lib)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_rank_predicted = lib_gnb_RANK.predict(X_test_lib)\n",
    "metrics_printer(y_test_lib,lib_rank_predicted,\"Liberal Ranked NB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lib_rank_predicted)\n",
    "print(label_encoder.inverse_transform(lib_rank_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_con_RANK = RandomForestClassifier(max_depth= None, random_state=0)\n",
    "rf_con_RANK.fit(X_train_con, y_train_con)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of conservative Random Forest  0.5506654835847382\n",
      "[[1570 1260]\n",
      " [1272 1533]]\n",
      "Accuracy:  0.5506654835847382\n",
      "Sensitivity:  0.546524064171123\n",
      "Specificity:  0.5547703180212014\n"
     ]
    }
   ],
   "source": [
    "rf_con_RANK_predicted = rf_con_RANK.predict(X_test_con)\n",
    "\n",
    "\n",
    "print(\"Accuracy of conservative Random Forest \", accuracy_score(y_test_con,rf_con_RANK_predicted))\n",
    "\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test_con,rf_con_RANK_predicted).ravel()\n",
    "\n",
    "print(metrics.confusion_matrix(y_test_con,rf_con_RANK_predicted))\n",
    "\n",
    "# print(\"tn\",tn, \"fp\",fp, \"fn\",fn,\"tp\", tp)\n",
    "\n",
    "metrics_printer(y_test_con,rf_con_RANK_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conservative RF\n",
      "Accuracy:  0.5506654835847382\n",
      "Sensitivity:  0.546524064171123\n",
      "Specificity:  0.5547703180212014\n"
     ]
    }
   ],
   "source": [
    "metrics_printer(y_test_con,rf_con_RANK_predicted,\"Conservative RF\")\n",
    "# print(rf_con_RANK_predicted)\n",
    "# print(label_encoder.inverse_transform(rf_con_RANK_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest:\n",
    "_Normalistion point @ 8_\n",
    "Accuracy of conservative Random Forest  0.9242757609094243\n",
    "\n",
    "Sensitivity = 0.9872486512996567\n",
    "Specificity = 0.023842917251051893\n",
    "\n",
    "[   17   696]\n",
    "[  130 10065]\n",
    "\n",
    "---------------------------------------------------------------\n",
    " \n",
    "_Normalisation point @ 7_\n",
    "Accuracy of conservative Random Forest  0.8423175650898423\n",
    "\n",
    "Sensitivity = 0.9872803708095289\n",
    "Specificity = 0.04595879556259905\n",
    "\n",
    "[  29 1602]\n",
    "[ 118 9159]\n",
    "\n",
    "---------------------------------------------------------------\n",
    " \n",
    "_Normalisatin point @ 6\n",
    "Accuracy of conservative Random Forest  0.7326732673267327\n",
    "\n",
    "Sensitivity = 0.9873276183376817\n",
    "Specificity = 0.015739769150052464\n",
    "\n",
    "[  45 2814]\n",
    "[ 102 7947]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-e34a0a8b260f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mAccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mTN\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mTN\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mSensitivity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTP\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mSpecificity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTN\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTN\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TP' is not defined"
     ]
    }
   ],
   "source": [
    "Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "Sensitivity = TP / (TP + FN)\n",
    "Specificity = TN / (TN + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity(TP, FN):\n",
    "    sensitivity = (TP / (TP + FN))\n",
    "   # print(sensitivity)\n",
    "    return sensitivity\n",
    "\n",
    "def specificity (TN, FP):\n",
    "    specificity = (TN / (TN + FP))\n",
    "   # print(specificity)\n",
    "    return specificity\n",
    "\n",
    "# print(sensitivity(tp,fn))\n",
    "# print(specificity( tn,fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
