{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4033\n",
      "0    0\n",
      "1    1\n",
      "2    5\n",
      "3    0\n",
      "4    5\n",
      "Name: lrscale, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv(\"pvq21_REVERSED_CENTRED.csv\", sep=',')\n",
    "lib_dataframe = data.copy()\n",
    "con_dataframe = data.copy()\n",
    "\n",
    "ub_dataframe = data.copy()\n",
    "((ub_dataframe[ub_dataframe['lrscale'] > 7].shape[0])/ ub_dataframe.shape[0]) *100\n",
    "\n",
    "\n",
    "lrscale_balanced = ub_dataframe['lrscale']\n",
    "\n",
    "print(ub_dataframe[ub_dataframe['lrscale'] == 7].shape[0])\n",
    "\n",
    "lrscale_balanced.hist(bins=11, figsize=[14,6])\n",
    "\n",
    "print(ub_dataframe['lrscale'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing the data\n",
    "Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Randomise dataframe\n",
    "2. counter variable = 0\n",
    "3. Go through the dataframe       *Or actually just pick all instances over this lr threshold* \n",
    "    3.1 For ever lrscore > threshold\n",
    "        3.2 Add to a new dataframe\n",
    "        3.3 counter ++ \n",
    "     \n",
    "4. While the new (balancer) dataframe is <= to the 50% of length of the full dataframe \n",
    "\n",
    "    4.1 Copy to itself\n",
    "    \n",
    "    \n",
    "5. Attach balancer dataframe to the previous data frame\n",
    "6. Return new dataframe \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36360\n",
      "(36360, 13)\n"
     ]
    }
   ],
   "source": [
    "#Some exploration:\n",
    "print(len(ub_dataframe))\n",
    "print(ub_dataframe.shape)\n",
    "\n",
    "\n",
    "def balance_samples(unbalanced_dataframe, lrthreshold):\n",
    "    \"\"\"Return a balanced dataframe i.e. consisting at 50% of the examples/cases above the lrthreshold (not inclusive)\"\"\"\n",
    "    balancer_dataframe = pd.DataFrame()\n",
    "\n",
    "    balancer_dataframe = unbalanced_dataframe[unbalanced_dataframe['lrscale'] > lrthreshold].copy()\n",
    "\n",
    "    #Calculate the 50% \n",
    "    half_value = int(len(unbalanced_dataframe)/2)\n",
    "\n",
    "\n",
    "    #The difference to getting a number of samples equal to 50 % of the original dataset\n",
    "   # dif_half = half_value - len(balancer_dataframe)\n",
    "\n",
    "    copy_balancer_dataframe = balancer_dataframe.sample(n = half_value, replace=True).reset_index(drop=True)\n",
    "    \n",
    "    balancer_dataframe = pd.concat([balancer_dataframe,copy_balancer_dataframe], axis=0)\n",
    "\n",
    "    balanced_df = pd.concat([unbalanced_dataframe,balancer_dataframe], axis=0)\n",
    "\n",
    "    balanced_df = balanced_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    return balanced_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersample(unbalanced_dataframe, lrthreshold, skew_distribution = 0.5):\n",
    "    \"\"\"Return a balanced dataframe i.e. consisting at 50% of the examples/cases above the lrthreshold (inclusive)\"\"\"\n",
    "    balancer_dataframe = unbalanced_dataframe.copy()\n",
    "    #balancer_data\n",
    "    minority_df = balancer_dataframe[balancer_dataframe['lrscale'] > lrthreshold]\n",
    "    minority_count = minority_df.shape[0]\n",
    "\n",
    "    print(\"minority_count\", minority_count)\n",
    "\n",
    "    print(\"TESTHOWMANY??\", balancer_dataframe[balancer_dataframe['lrscale'] <= lrthreshold].shape[0])\n",
    "    #pick and remove a random sample of instances under the set threshold\n",
    "    majority_balancer = balancer_dataframe[balancer_dataframe['lrscale'] <= lrthreshold].sample(n=minority_count, replace = False)\n",
    "    \n",
    "    balanced_df = pd.concat([minority_df,majority_balancer],axis=0)\n",
    "    balanced_df = balanced_df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "#     print(\"majority balancer\", majority_balancer.shape[0])\n",
    "#     print(\"minority df\", minority_df.shape[0])\n",
    "#     print(\"balanced df\", balanced_df.shape[0])\n",
    "\n",
    "    \n",
    "    return balanced_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_count 5358\n",
      "TESTHOWMANY?? 31002\n"
     ]
    }
   ],
   "source": [
    "lrthreshold = 6\n",
    "# print(con_dataframe.head())\n",
    "balanced_dataframe = undersample(ub_dataframe, lrthreshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "undersampled_dataframe = undersample(ub_dataframe,lrthreshold)\n",
    "\n",
    "\n",
    "\n",
    "print(type(balanced_dataframe))\n",
    "print(type(undersampled_dataframe))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59898, 13)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576000x72000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(undersampled_dataframe.shape)\n",
    "\n",
    "# balanced_dataframe[balanced_dataframe['lrscale'] > 7].shape[0]\n",
    "# lrscale_balanced = undersampled_dataframe['lrscale']\n",
    "# lrscale_balanced.hist(bins=10, figsize=[14,6])\n",
    "\n",
    "def hist_plotter(dataframe,threshold):\n",
    "    lrscale_balanced = dataframe['lrscale']\n",
    "    n,bins,patches = plt.hist(lrscale_balanced, bins=[0, 1, 2, 3, 4, 5, 6,7,8,9,10], color='b')\n",
    "    plt.title(f\"Distribution on threshold > {threshold}\") \n",
    "    plt.figure(figsize=(8000,1000))\n",
    "    \n",
    "    for patch_num in range(threshold, 10):\n",
    "        patches[patch_num].set_fc('g')\n",
    "\n",
    "hist_plotter(undersampled_dataframe,lrthreshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percenatge of scores over 7  48.242011419413004\n"
     ]
    }
   ],
   "source": [
    "print(f\"The percenatge of scores over {lrthreshold} \",((undersampled_dataframe[undersampled_dataframe['lrscale'] > lrthreshold].shape[0]) / undersampled_dataframe.shape[0])*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  lrscale  universalism  achievement  benevolence  \\\n",
      "0       34642       10          3.25     4.416667     4.416667   \n",
      "1       26291        8          3.40     3.566667     3.566667   \n",
      "2       35044        8          4.30     3.466667     4.966667   \n",
      "3       22823        5          4.00     3.000000     4.000000   \n",
      "4       30867        7          4.35     4.516667     2.516667   \n",
      "\n",
      "   self_direction  stimulation  hedonism     power  security  conformity  \\\n",
      "0        4.416667     4.416667  4.416667  2.916667  1.916667    1.916667   \n",
      "1        4.566667     3.066667  3.066667  3.066667  4.066667    4.066667   \n",
      "2        3.966667     2.466667  2.466667  3.466667  2.966667    3.466667   \n",
      "3        4.000000     3.500000  3.000000  3.000000  4.000000    3.000000   \n",
      "4        3.016667     1.016667  3.016667  4.016667  5.016667    4.516667   \n",
      "\n",
      "   tradition     p_avg  \n",
      "0   2.916667  4.583333  \n",
      "1   2.566667  3.433333  \n",
      "2   3.466667  3.533333  \n",
      "3   3.500000  4.500000  \n",
      "4   3.016667  4.483333  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(balanced_dataframe.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the (almost) balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_dataframe = undersampled_dataframe.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59898, 13)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_dataframe.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bin the data for each dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_lib (value):\n",
    "\n",
    "        if value < 3:\n",
    "            return 1#\"liberal\" #liberal\n",
    "        else:\n",
    "            return 0#\"moderate\" #moderate\n",
    "\n",
    "def normalise_con (value):\n",
    "        \n",
    "        if value > lrthreshold:\n",
    "            return 1#\"conservative\" #conservative\n",
    "        else:\n",
    "            return 0#\"moderate\" #moderate\n",
    "        \n",
    "\n",
    "lib_dataframe['lrscale'] = lib_dataframe['lrscale'].apply(normalise_lib)\n",
    "con_dataframe['lrscale'] = con_dataframe['lrscale'].apply(normalise_con)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    0\n",
      "4    0\n",
      "Name: lrscale, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_lib = lib_dataframe.iloc[:, 2:12].copy()\n",
    "y_lib = lib_dataframe.iloc[:,1].copy()\n",
    "#Now the data frame for conservative prediction\n",
    "X_con = con_dataframe.iloc[:, 2:12].copy()\n",
    "y_con = con_dataframe.iloc[:,1].copy()\n",
    "\n",
    "print(y_con.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28896\n",
      "31002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48.242011419413004"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list(y_con).count(1))\n",
    "print(list(y_con).count(0))\n",
    "\n",
    "con_lib_ratio = (list(y_con).count(1)/(list(y_con).count(0) + list(y_con).count(1)) * 100)\n",
    "con_lib_ratio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(sparse=False)\n",
    "y_lib_onehot = enc.fit_transform(y_lib.to_numpy().reshape(-1, 1))\n",
    "y_con_onehot = enc.fit_transform(y_con.to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Encoding instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_lib_onehot = label_encoder.fit_transform(y_lib.copy())\n",
    "y_con_onehot = label_encoder.fit_transform(y_con.copy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lib_oh, X_test_lib_oh, y_train_lib_oh, y_test_lib_oh = train_test_split(X_lib, y_lib_onehot, test_size=0.25, random_state=10)\n",
    "X_train_con_oh, X_test_con_oh, y_train_con_oh, y_test_con_oh = train_test_split(X_con, y_con_onehot, test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call this function to perform cross validation to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(model):\n",
    "    #return scores\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "      normalize=False, positive=False, precompute=False, random_state=None,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class Lasso():\n",
    "lasso_LIB_model = Lasso(alpha=1.0)\n",
    "#fitting the liberal model\n",
    "lasso_LIB_model.fit(X_train_lib_oh,y_train_lib_oh)\n",
    "\n",
    "lasso_CON_model = Lasso(alpha=1.0)\n",
    "lasso_CON_model.fit(X_train_con_oh,y_train_con_oh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49943206 0.50056794]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:434: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lasso_lib_pred = lasso_LIB_model.predict(X_test_lib_oh)\n",
    "# print(lasso_lib_pred)\n",
    "\n",
    "#enc.inverse_transform([np.argmax(lasso_lib_pred[0, :])])\n",
    "# #print(lasso_lib_pred[0, :])\n",
    "# print(\"The ground truth labels:\")\n",
    "# #print(np.argmax(y_test_lib_oh, axis = 1))\n",
    "# print(\"Liberal LASSO accuracy: \")\n",
    "# #print(accuracy_score(y_test_lib_oh, lasso_lib_pred))#np.argmax(y_test_lib_oh, axis = 1), np.argmax(lasso_LIB_model.predict(X_test_lib_oh), axis=1)))\n",
    "# print(lasso_LIB_model.coef_) #feature significance\n",
    "# print()\n",
    "# print(lasso_CON_model.predict(X_test_con_oh))\n",
    "# print(\"The ground truth labels:\")\n",
    "# print(y_test_con_oh)\n",
    "lasso_CON_model.score(X_test_con_oh,y_test_con_oh)\n",
    "print(lasso_CON_model.intercept_)\n",
    "#con_preds = lasso_CON_model.predict(X_test_con_oh)\n",
    "\n",
    "\n",
    "# enc.fit_transform(y_test_con_oh)\n",
    "\n",
    "#metrics_printer(enc.inverse_transform(y_test_con_oh),enc.invrse_transform(y_test_con_oh))\n",
    "\n",
    "# for i in con_preds:\n",
    "#     print(enc.inverse_transform(i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TIP: One hot encoding does not work well with Logistic Regression; a one hot encoding will case the matrix of input data to become singular, meaning it cannot be inverted and the linear regression coefficients cannot be calculated using linear algebra. For these types of models a dummy variable encoding must be used instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So: Label encoding the data for the Logistic Regression (and the Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lib_cat = y_lib.copy()        #NOT SURE WHAT THIS STEP DOES, MAYBE IT IS REDUNDANT\n",
    "y_con_cat = y_con.copy()\n",
    "\n",
    "# y_lib_cat = y_lib_cat.astype('category')\n",
    "# y_con_cat = y_con_cat.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_lib_labelencoded = label_encoder.fit_transform(y_lib_cat)\n",
    "y_con_labelencoded = label_encoder.fit_transform(y_con_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling (only for CONSERVATIVE PREDICTION for now)\n",
    "\n",
    "https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/\n",
    "\n",
    "https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/\n",
    "\n",
    "Random oversampling involves randomly duplicating examples from the minority class and adding them to the training dataset.\n",
    "\n",
    "Examples from the training dataset are selected randomly with replacement. This means that examples from the minority class can be chosen and added to the new “more balanced” training dataset multiple times; they are selected from the original training dataset, added to the new training dataset, and then returned or “replaced” in the original dataset, allowing them to be selected again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22.1\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler \n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lib_l, X_test_lib_l, y_train_lib_l, y_test_lib_l = train_test_split(X_lib, y_lib_labelencoded, test_size=0.30, random_state=10)\n",
    "X_train_con_l, X_test_con_l, y_train_con_l, y_test_con_l = train_test_split(X_con, y_con_labelencoded, test_size=0.30, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_LIB = LogisticRegression(random_state=0)\n",
    "logistic_regression_LIB.fit(X_train_lib_l, y_train_lib_l)\n",
    "\n",
    "logistic_regression_CON = LogisticRegression(random_state=0)\n",
    "logistic_regression_CON.fit(X_train_con_l, y_train_con_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liberal LR predicts:  [0 0 0 ... 0 0 0]\n",
      "Ground truth:  [1 0 0 ... 0 0 0]\n",
      "0.8825632563256326\n",
      "Conservative LR predicts: \n",
      "Ground truth:  [1 0 0 ... 0 0 1]\n",
      "0.5908111988513999\n",
      "\n",
      "LIBERAL COEFFICIENTS\n",
      "[[ 0.49919619 -0.04080791 -0.13054757 -0.09643039 -0.14987894 -0.08033117\n",
      "  -0.15718796 -0.19202133 -0.16193753 -0.18695461]]\n",
      "\n",
      "CONSERVATIVE COEFFICIENTS\n",
      "[[-0.46179378 -0.02419632 -0.0664999   0.04237721  0.07434872 -0.01327747\n",
      "   0.09786605  0.15873358  0.05412356  0.21810127]]\n",
      "CONSEVATIVE LOGISTIC REGRESSION - BALANCED - Threshold at 8 \n",
      "Accuracy:  0.5908111988513999\n",
      "Sensitivity:  0.6391304347826087\n",
      "Specificity:  0.5433854907539118\n"
     ]
    }
   ],
   "source": [
    "LR_lib_pred = logistic_regression_LIB.predict(X_test_lib_l)\n",
    "print(\"Liberal LR predicts: \",LR_lib_pred )\n",
    "print(\"Ground truth: \", y_test_lib_l)\n",
    "\n",
    "print(accuracy_score(y_test_lib_l, LR_lib_pred))\n",
    "\n",
    "LR_con_pred = logistic_regression_CON.predict(X_test_con_l)\n",
    "print(\"Conservative LR predicts: \", )\n",
    "print(\"Ground truth: \", y_test_con_l)\n",
    "print(accuracy_score(y_test_con_l, LR_con_pred))\n",
    "print()\n",
    "print(\"LIBERAL COEFFICIENTS\")\n",
    "print(logistic_regression_LIB.coef_)\n",
    "\n",
    "print()\n",
    "print(\"CONSERVATIVE COEFFICIENTS\")\n",
    "print(logistic_regression_CON.coef_)\n",
    "\n",
    "# Liberal LR predicts:  [0 0 0 ... 0 0 0]\n",
    "# Ground truth:  [1 0 0 ... 0 0 0]\n",
    "# 0.8820682068206821\n",
    "# Conservative LR predicts: \n",
    "# Ground truth:  [0 0 0 ... 0 1 0]\n",
    "# 0.7358635863586359\n",
    "\n",
    "\n",
    "metrics_printer(y_test_con_l, LR_con_pred, f\"CONSEVATIVE LOGISTIC REGRESSION - BALANCED - Threshold at {lrthreshold} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result interpretation:\n",
    "\n",
    "LIBERAL COEFFICIENTS\n",
    "[[ 0.64696149  0.10334159  0.00508842  0.03620765 -0.00407959  0.05359682\n",
    "  -0.02097152 -0.05334792 -0.013917   -0.057601  ]]\n",
    "\n",
    "CONSERVATIVE COEFFICIENTS\n",
    "[[-0.39614516  0.027852    0.03136662  0.11140505  0.06367177 -0.00044922\n",
    "   0.11708522  0.08849489  0.14891201  0.24233131]]\n",
    "   \n",
    "The external correlations match those given at https://gosling.psy.utexas.edu/wp-content/uploads/2016/12/Sandy-et-al-JPA-2016-Brief-values-measures.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix: \n",
    "Shows that the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liberal confusion matrix: \n",
      " [[9627    0]\n",
      " [1281    0]]\n",
      "conservative confusion matrix: \n",
      " [[916 683]\n",
      " [661 955]]\n"
     ]
    }
   ],
   "source": [
    "cm_lib = metrics.confusion_matrix(y_test_lib_l, LR_lib_pred)\n",
    "print(\"liberal confusion matrix: \\n\", cm_lib)\n",
    "\n",
    "cm_con = metrics.confusion_matrix(y_test_con_l, LR_con_pred)\n",
    "print(\"conservative confusion matrix: \\n\", cm_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88476348 0.88476348 0.88476348 0.88476348 0.88476348 0.88476348\n",
      " 0.88476348 0.88476348 0.8850385  0.8850385 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_LIB_CVVVVV = LogisticRegression(random_state=0)\n",
    "\n",
    "cv_results_lib = cross_validate(logistic_regression_LIB_CVVVVV, X_lib, y_lib_labelencoded, cv=10)\n",
    "\n",
    "cv_results_con = cross_validate(logistic_regression_CON, X_con, y_con_labelencoded, cv=3)\n",
    "\n",
    "print(cv_results_lib['test_score'])\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "… there are occasions when a complete set of dummy variables is useful. For example, the splits in a tree-based model are more interpretable when the dummy variables encode all the information for that predictor. We recommend using the full set if dummy variables when working with tree-based models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of liberal Random Forest  0.5145764576457645\n",
      "Accuracy of conservative Random Forest  0.5721464465183058\n"
     ]
    }
   ],
   "source": [
    "rf_lib = RandomForestClassifier(max_depth=None, random_state=0)\n",
    "rf_lib.fit(X_train_lib_l, y_train_lib_l)\n",
    "\n",
    "rf_con = RandomForestClassifier(max_depth= None, random_state=0)\n",
    "rf_lib.fit(X_train_con_l, y_train_con_l)\n",
    "\n",
    "\n",
    "rf_lib_predicted = rf_lib.predict(X_test_lib_l)\n",
    "rf_con_predicted = rf_lib.predict(X_test_con_l)\n",
    "\n",
    "print(\"Accuracy of liberal Random Forest \", accuracy_score(y_test_lib_l,rf_lib_predicted))\n",
    "print(\"Accuracy of conservative Random Forest \", accuracy_score(y_test_con_l,rf_con_predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liberal confusion matrix: \n",
      " [[5124 4503]\n",
      " [ 792  489]]\n",
      "conservative confusion matrix: \n",
      " [[397 306]\n",
      " [290 400]]\n"
     ]
    }
   ],
   "source": [
    "rf_cm_lib = metrics.confusion_matrix(y_test_lib_l, rf_lib_predicted)\n",
    "print(\"liberal confusion matrix: \\n\", rf_cm_lib)\n",
    "\n",
    "rf_cm_con = metrics.confusion_matrix(y_test_con_l, rf_con_predicted)\n",
    "print(\"conservative confusion matrix: \\n\", rf_cm_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Conservative - BALANCED DATA - threshold at 8\n",
      "Accuracy:  0.5721464465183058\n",
      "Sensitivity:  0.5797101449275363\n",
      "Specificity:  0.5647226173541963\n"
     ]
    }
   ],
   "source": [
    "metrics_printer(y_test_con_l, rf_con_predicted, f\"Random Forest Conservative - BALANCED DATA - threshold at {lrthreshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes (ToDo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lib_gnb = GaussianNB()\n",
    "\n",
    "lib_gnb.fit(X_train_lib_l, y_train_lib_l)\n",
    "\n",
    "\n",
    "con_gnb = GaussianNB()\n",
    "\n",
    "con_gnb.fit(X_train_con_l, y_train_con_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8735790245691236\n",
      "[[9454  173]\n",
      " [1206   75]]\n",
      "9454 173 1206 75\n",
      "0.7355152181884855\n",
      "[[7963   86]\n",
      " [2799   60]]\n"
     ]
    }
   ],
   "source": [
    "lib_gnb_predicted = lib_gnb.predict(X_test_lib_l)\n",
    "gnb_cm_lib = metrics.confusion_matrix(y_test_lib_l,lib_gnb_predicted)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test_lib_l,lib_gnb_predicted).ravel()\n",
    "\n",
    "con_gnb_predicted = con_gnb.predict(X_test_con_l)\n",
    "gnb_cm_con = metrics.confusion_matrix(y_test_con_l,con_gnb_predicted)\n",
    "print(accuracy_score(y_test_lib_l,lib_gnb_predicted))\n",
    "print(gnb_cm_lib)\n",
    "print(tn, fp, fn, tp)\n",
    "print(accuracy_score(y_test_con_l,con_gnb_predicted))\n",
    "print(gnb_cm_con)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection - experiments: \n",
    "*first attempt on the conservative classifier*\n",
    "\n",
    "Liberal significant features: \n",
    "\n",
    "Conservative significant features: Conformity, Tradition, Universalism, Self direction, Stimulation, Hedonism, Achievement (power), Security\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>universalism</th>\n",
       "      <th>achievement</th>\n",
       "      <th>self_direction</th>\n",
       "      <th>stimulation</th>\n",
       "      <th>hedonism</th>\n",
       "      <th>power</th>\n",
       "      <th>security</th>\n",
       "      <th>conformity</th>\n",
       "      <th>tradition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.65</td>\n",
       "      <td>2.816667</td>\n",
       "      <td>4.316667</td>\n",
       "      <td>3.316667</td>\n",
       "      <td>3.816667</td>\n",
       "      <td>3.816667</td>\n",
       "      <td>2.316667</td>\n",
       "      <td>3.816667</td>\n",
       "      <td>4.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.70</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>4.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.35</td>\n",
       "      <td>3.516667</td>\n",
       "      <td>3.516667</td>\n",
       "      <td>3.516667</td>\n",
       "      <td>4.016667</td>\n",
       "      <td>3.016667</td>\n",
       "      <td>3.516667</td>\n",
       "      <td>2.016667</td>\n",
       "      <td>3.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.90</td>\n",
       "      <td>4.566667</td>\n",
       "      <td>4.566667</td>\n",
       "      <td>3.066667</td>\n",
       "      <td>2.566667</td>\n",
       "      <td>1.066667</td>\n",
       "      <td>4.566667</td>\n",
       "      <td>3.566667</td>\n",
       "      <td>3.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.70</td>\n",
       "      <td>3.533333</td>\n",
       "      <td>4.533333</td>\n",
       "      <td>3.533333</td>\n",
       "      <td>3.533333</td>\n",
       "      <td>2.533333</td>\n",
       "      <td>3.033333</td>\n",
       "      <td>2.033333</td>\n",
       "      <td>3.533333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   universalism  achievement  self_direction  stimulation  hedonism     power  \\\n",
       "0          3.65     2.816667        4.316667     3.316667  3.816667  3.816667   \n",
       "1          3.70     4.700000        5.200000     2.700000  3.200000  1.700000   \n",
       "2          3.35     3.516667        3.516667     3.516667  4.016667  3.016667   \n",
       "3          3.90     4.566667        4.566667     3.066667  2.566667  1.066667   \n",
       "4          4.70     3.533333        4.533333     3.533333  3.533333  2.533333   \n",
       "\n",
       "   security  conformity  tradition  \n",
       "0  2.316667    3.816667   4.316667  \n",
       "1  5.200000    1.700000   4.700000  \n",
       "2  3.516667    2.016667   3.516667  \n",
       "3  4.566667    3.566667   3.066667  \n",
       "4  3.033333    2.033333   3.533333  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_con_featureslected = X_con.copy().drop(['benevolence'], axis = 1)\n",
    "\n",
    "X_con_featureslected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_con_onehot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-493eea97b607>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_con_oh_fs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_con_oh_fs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_con_oh_fs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_con_oh_fs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_con_featureslected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_con_onehot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_con_onehot' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_con_oh_fs, X_test_con_oh_fs, y_train_con_oh_fs, y_test_con_oh_fs = train_test_split(X_con_featureslected, y_con_onehot, test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_con_gnb = GaussianNB()\n",
    "\n",
    "fs_con_gnb.fit(X_train_con_oh_fs, y_train_con_oh_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6657   34 2378   21]\n",
      "0.7346534653465346\n",
      "[0 0 0 ... 0 0 0]\n",
      "[[6657   34]\n",
      " [2378   21]]\n",
      "9035\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "fs_con_gnb_predicted = fs_con_gnb.predict(X_test_con_oh_fs)\n",
    "fs_gnb_cm_con = metrics.confusion_matrix(y_test_con_oh_fs,fs_con_gnb_predicted)\n",
    "print(metrics.confusion_matrix(y_test_con_oh_fs,fs_con_gnb_predicted).ravel())\n",
    "print(accuracy_score(y_test_con_oh_fs,fs_con_gnb_predicted))\n",
    "\n",
    "print(label_encoder.inverse_transform(fs_con_gnb_predicted))\n",
    "print(metrics.confusion_matrix(y_test_con_oh_fs,fs_con_gnb_predicted))\n",
    "\n",
    "print(list(fs_con_gnb_predicted).count(0))\n",
    "print(list(label_encoder.inverse_transform(fs_con_gnb_predicted)).count('conservative'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations: \n",
    "(with normalisations of conservatives over 7 (i.e. > 7)\n",
    "- NB using OneHot encoding and having removed Benevolence: 93% accuracy\n",
    "[   2  605]\n",
    " [   4 8479]]\n",
    " \n",
    "- NB using OneHot encoding and having removed Benevelonece & Power: 93% accuracy\n",
    "[[   0  607]\n",
    " [   2 8481]]\n",
    "\n",
    "-  NB using Label encoding and having removed Benevolence: 84.8% accuracy\n",
    "[[  10 1370]\n",
    " [   8 7702]]\n",
    " \n",
    "- NB using Label encoding and having removed Benevolence & Power: 84.8%\n",
    "[[   6 1374]\n",
    " [   3 7707]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_rf_con = RandomForestClassifier(max_depth=None, random_state=0)\n",
    "fs_rf_con.fit(X_train_con_oh_fs, y_train_con_oh_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7346534653465346\n",
      "[[6657   34]\n",
      " [2378   21]]\n"
     ]
    }
   ],
   "source": [
    "fs_rf_con_predicted = fs_con_gnb.predict(X_test_con_oh_fs)\n",
    "print(accuracy_score(y_test_con_oh_fs,fs_rf_con_predicted))\n",
    "print(metrics.confusion_matrix(y_test_con_oh_fs,fs_rf_con_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking Algorithms\n",
    "\n",
    "- Training data consists of lists of items with some partial order specified between items in each list. This order is typically induced by giving a numerical or ordinal score or a binary judgment (e.g. \"relevant\" or \"not relevant\") for each item. The ranking model purposes to rank, i.e. producing a permutation of items in new, unseen lists in a similar way to rankings in the training data.\n",
    "\n",
    "Ideas: \n",
    "    - Rank based on 'higher value = most important' (i.e. based on the assumption that conservatives have similar higher values  and similar lower values)\n",
    "    - Rank based  on ''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lib_RANK1 = X_lib.copy()\n",
    "X_con_RANK1 = X_con.copy()\n",
    "\n",
    "# X_lib_RANK1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_value (dataframe):\n",
    "    df = dataframe.copy()\n",
    "    df_comps = pd.DataFrame()\n",
    "    col_name =''\n",
    "    for column_name, data in df.iteritems():\n",
    "        for other_column_name, other_data in df.iteritems():\n",
    "            if column_name != other_column_name:\n",
    "                comp_col_name = column_name + ' < ' + other_column_name\n",
    "                df_comps[comp_col_name] = df[column_name] < df[other_column_name]\n",
    "\n",
    "    return df_comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_con_RANK = relative_value(X_con_RANK1)\n",
    "X_lib_RANK = X_con_RANK.copy()\n",
    "\n",
    "len(X_lib_RANK.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_lib = lib_dataframe.iloc[:, 2:12].copy()\n",
    "# y_lib = lib_dataframe.iloc[:,1].copy()\n",
    "# #Now the data frame for conservative prediction\n",
    "# X_con = con_dataframe.iloc[:, 2:12].copy()\n",
    "# y_con = con_dataframe.iloc[:,1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_lib_labelencoded = label_encoder.fit_transform(y_lib)\n",
    "y_con_labelencoded = label_encoder.fit_transform(y_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(sparse=False)\n",
    "y_lib_onehot = enc.fit_transform(y_lib.to_numpy().reshape(-1, 1))\n",
    "y_con_onehot = enc.fit_transform(y_con.to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_lib, X_test_lib, y_train_lib, y_test_lib = train_test_split(X_lib_RANK, y_lib_labelencoded, test_size=0.30, random_state=10)\n",
    "X_train_con, X_test_con, y_train_con, y_test_con = train_test_split(X_con_RANK, y_con_labelencoded, test_size=0.30, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9284"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y_test_con).count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_printer (ground_truth, model_predicted, classification_target = None):\n",
    "    \"\"\"Return sensitivity,specificity,accuracy & if given classification target\"\"\"\n",
    "    if classification_target != None: \n",
    "        print(classification_target)\n",
    "    tnegative, fpositive, fnegative, tpositive = metrics.confusion_matrix(ground_truth,model_predicted).ravel()\n",
    "    print(\"Accuracy: \", accuracy_score(ground_truth,model_predicted))\n",
    "    print(\"Sensitivity: \", sensitivity(tpositive,fnegative))\n",
    "    print(\"Specificity: \", specificity(tnegative,fpositive))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_gnb_RANK = GaussianNB()\n",
    "con_gnb_RANK.fit(X_train_con, y_train_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5681135225375626\n",
      "Sensitivity:  0.490329265484688\n",
      "Specificity:  0.6408875484704869\n"
     ]
    }
   ],
   "source": [
    "con_RANK_predicted = con_gnb_RANK.predict(X_test_con)\n",
    "# print(type(con_RANK_predicted))\n",
    "# print(accuracy_score(y_test_con,con_RANK_predicted))\n",
    "# tnegative, fpositive, fnegative, tpositive = metrics.confusion_matrix(y_test_con,con_RANK_predicted).ravel()\n",
    "# print(\"tn\",tnegative, \"fp\",fpositive, \"fn\",fnegative,\"tp\", tpositive)\n",
    "# print(metrics.confusion_matrix(y_test_con,con_RANK_predicted))\n",
    "\n",
    "# sensitivity(tpositive,fnegative)\n",
    "# specificity(tnegative,fpositive)\n",
    "\n",
    "# (TP / (TP + FN))\n",
    "# (TN / (TN + FP))\n",
    "\n",
    "metrics_printer(y_test_con,con_RANK_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"LIBERAL NB RANKED\"\"\"\n",
    "\n",
    "lib_gnb_RANK = GaussianNB()\n",
    "#X_train_lib, X_test_lib, y_train_lib, y_test_lib\n",
    "lib_gnb_RANK.fit(X_train_lib, y_train_lib)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_rank_predicted = lib_gnb_RANK.predict(X_test_lib)\n",
    "metrics_printer(y_test_lib,lib_rank_predicted,\"Liberal Ranked NB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lib_rank_predicted)\n",
    "print(label_encoder.inverse_transform(lib_rank_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_con_RANK = RandomForestClassifier(max_depth= None, random_state=0)\n",
    "rf_con_RANK.fit(X_train_con, y_train_con)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of conservative Random Forest  0.9540901502504173\n",
      "[[8586  698]\n",
      " [ 127 8559]]\n",
      "Accuracy:  0.9540901502504173\n",
      "Sensitivity:  0.9853787704351831\n",
      "Specificity:  0.9248168892718656\n"
     ]
    }
   ],
   "source": [
    "rf_con_RANK_predicted = rf_con_RANK.predict(X_test_con)\n",
    "\n",
    "\n",
    "print(\"Accuracy of conservative Random Forest \", accuracy_score(y_test_con,rf_con_RANK_predicted))\n",
    "\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test_con,rf_con_RANK_predicted).ravel()\n",
    "\n",
    "print(metrics.confusion_matrix(y_test_con,rf_con_RANK_predicted))\n",
    "\n",
    "# print(\"tn\",tn, \"fp\",fp, \"fn\",fn,\"tp\", tp)\n",
    "\n",
    "metrics_printer(y_test_con,rf_con_RANK_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conservative RF\n",
      "Accuracy:  0.9540901502504173\n",
      "Sensitivity:  0.9853787704351831\n",
      "Specificity:  0.9248168892718656\n"
     ]
    }
   ],
   "source": [
    "metrics_printer(y_test_con,rf_con_RANK_predicted,\"Conservative RF\")\n",
    "# print(rf_con_RANK_predicted)\n",
    "# print(label_encoder.inverse_transform(rf_con_RANK_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest:\n",
    "_Normalistion point @ 8_\n",
    "Accuracy of conservative Random Forest  0.9242757609094243\n",
    "\n",
    "Sensitivity = 0.9872486512996567\n",
    "Specificity = 0.023842917251051893\n",
    "\n",
    "[   17   696]\n",
    "[  130 10065]\n",
    "\n",
    "---------------------------------------------------------------\n",
    " \n",
    "_Normalisation point @ 7_\n",
    "Accuracy of conservative Random Forest  0.8423175650898423\n",
    "\n",
    "Sensitivity = 0.9872803708095289\n",
    "Specificity = 0.04595879556259905\n",
    "\n",
    "[  29 1602]\n",
    "[ 118 9159]\n",
    "\n",
    "---------------------------------------------------------------\n",
    " \n",
    "_Normalisatin point @ 6\n",
    "Accuracy of conservative Random Forest  0.7326732673267327\n",
    "\n",
    "Sensitivity = 0.9873276183376817\n",
    "Specificity = 0.015739769150052464\n",
    "\n",
    "[  45 2814]\n",
    "[ 102 7947]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-e34a0a8b260f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mAccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mTN\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mTN\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mSensitivity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTP\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mSpecificity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTN\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTN\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TP' is not defined"
     ]
    }
   ],
   "source": [
    "Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "Sensitivity = TP / (TP + FN)\n",
    "Specificity = TN / (TN + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity(TP, FN):\n",
    "    sensitivity = (TP / (TP + FN))\n",
    "   # print(sensitivity)\n",
    "    return sensitivity\n",
    "\n",
    "def specificity (TN, FP):\n",
    "    specificity = (TN / (TN + FP))\n",
    "   # print(specificity)\n",
    "    return specificity\n",
    "\n",
    "# print(sensitivity(tp,fn))\n",
    "# print(specificity( tn,fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
