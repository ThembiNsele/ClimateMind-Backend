{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4033\n",
      "0    0\n",
      "1    1\n",
      "2    5\n",
      "3    0\n",
      "4    5\n",
      "Name: lrscale, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv(\"pvq21_REVERSED_CENTRED.csv\", sep=',')\n",
    "lib_dataframe = data.copy()\n",
    "con_dataframe = data.copy()\n",
    "\n",
    "ub_dataframe = data.copy()\n",
    "((ub_dataframe[ub_dataframe['lrscale'] > 7].shape[0])/ ub_dataframe.shape[0]) *100\n",
    "\n",
    "\n",
    "lrscale_balanced = ub_dataframe['lrscale']\n",
    "\n",
    "print(ub_dataframe[ub_dataframe['lrscale'] == 7].shape[0])\n",
    "\n",
    "lrscale_balanced.hist(bins=11, figsize=[14,6])\n",
    "\n",
    "print(ub_dataframe['lrscale'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing the data\n",
    "Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Randomise dataframe\n",
    "2. counter variable = 0\n",
    "3. Go through the dataframe       *Or actually just pick all instances over this lr threshold* \n",
    "    3.1 For ever lrscore > threshold\n",
    "        3.2 Add to a new dataframe\n",
    "        3.3 counter ++ \n",
    "     \n",
    "4. While the new (balancer) dataframe is <= to the 50% of length of the full dataframe \n",
    "\n",
    "    4.1 Copy to itself\n",
    "    \n",
    "    \n",
    "5. Attach balancer dataframe to the previous data frame\n",
    "6. Return new dataframe \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36360\n",
      "(36360, 13)\n"
     ]
    }
   ],
   "source": [
    "#Some exploration:\n",
    "print(len(ub_dataframe))\n",
    "print(ub_dataframe.shape)\n",
    "\n",
    "\n",
    "def balance_samples(unbalanced_dataframe, lrthreshold):\n",
    "    \"\"\"Return a balanced dataframe i.e. consisting at 50% of the examples/cases above the lrthreshold (not inclusive)\"\"\"\n",
    "    balancer_dataframe = pd.DataFrame()\n",
    "\n",
    "    balancer_dataframe = unbalanced_dataframe[unbalanced_dataframe['lrscale'] > lrthreshold].copy()\n",
    "\n",
    "    #Calculate the 50% \n",
    "    half_value = int(len(unbalanced_dataframe)/2)\n",
    "\n",
    "\n",
    "    #The difference to getting a number of samples equal to 50 % of the original dataset\n",
    "   # dif_half = half_value - len(balancer_dataframe)\n",
    "\n",
    "    copy_balancer_dataframe = balancer_dataframe.sample(n = half_value, replace=True).reset_index(drop=True)\n",
    "    \n",
    "    balancer_dataframe = pd.concat([balancer_dataframe,copy_balancer_dataframe], axis=0)\n",
    "\n",
    "    balanced_df = pd.concat([unbalanced_dataframe,balancer_dataframe], axis=0)\n",
    "\n",
    "    balanced_df = balanced_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    return balanced_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersample(unbalanced_dataframe, lrthreshold, skew_distribution = 0.5):\n",
    "    \"\"\"Return a balanced dataframe i.e. consisting at 50% of the examples/cases above the lrthreshold (inclusive)\"\"\"\n",
    "    balancer_dataframe = unbalanced_dataframe.copy()\n",
    "    #balancer_data\n",
    "    minority_df = balancer_dataframe[balancer_dataframe['lrscale'] > lrthreshold]\n",
    "    minority_count = minority_df.shape[0]\n",
    "\n",
    "    print(\"minority_count\", minority_count)\n",
    "\n",
    "    print(\"TESTHOWMANY??\", balancer_dataframe[balancer_dataframe['lrscale'] <= lrthreshold].shape[0])\n",
    "    #pick and remove a random sample of instances under the set threshold\n",
    "    majority_balancer = balancer_dataframe[balancer_dataframe['lrscale'] <= lrthreshold].sample(n=minority_count, replace = False)\n",
    "    \n",
    "    balanced_df = pd.concat([minority_df,majority_balancer],axis=0)\n",
    "    balanced_df = balanced_df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "#     print(\"majority balancer\", majority_balancer.shape[0])\n",
    "#     print(\"minority df\", minority_df.shape[0])\n",
    "#     print(\"balanced df\", balanced_df.shape[0])\n",
    "\n",
    "    \n",
    "    return balanced_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_count 9391\n",
      "TESTHOWMANY?? 26969\n"
     ]
    }
   ],
   "source": [
    "lrthreshold = 6\n",
    "# print(con_dataframe.head())\n",
    "balanced_dataframe = undersample(ub_dataframe, lrthreshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_count 9391\n",
      "TESTHOWMANY?? 26969\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "undersampled_dataframe = undersample(ub_dataframe,lrthreshold)\n",
    "\n",
    "\n",
    "\n",
    "print(type(balanced_dataframe))\n",
    "print(type(undersampled_dataframe))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18782, 13)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576000x72000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(undersampled_dataframe.shape)\n",
    "\n",
    "# balanced_dataframe[balanced_dataframe['lrscale'] > 7].shape[0]\n",
    "# lrscale_balanced = undersampled_dataframe['lrscale']\n",
    "# lrscale_balanced.hist(bins=10, figsize=[14,6])\n",
    "\n",
    "def hist_plotter(dataframe,threshold):\n",
    "    lrscale_balanced = dataframe['lrscale']\n",
    "    n,bins,patches = plt.hist(lrscale_balanced, bins=[0, 1, 2, 3, 4, 5, 6,7,8,9,10], color='b')\n",
    "    plt.title(f\"Distribution on threshold > {threshold}\") \n",
    "    plt.figure(figsize=(8000,1000))\n",
    "    \n",
    "    for patch_num in range(threshold, 10):\n",
    "        patches[patch_num].set_fc('g')\n",
    "\n",
    "hist_plotter(undersampled_dataframe,lrthreshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percenatge of scores over 6  50.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"The percenatge of scores over {lrthreshold} \",((undersampled_dataframe[undersampled_dataframe['lrscale'] > lrthreshold].shape[0]) / undersampled_dataframe.shape[0])*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  lrscale  universalism  achievement  benevolence  \\\n",
      "0       13896        3          4.65     0.983333     4.983333   \n",
      "1        4578        3          4.05     3.216667     4.716667   \n",
      "2       38969        4          4.25     4.583333     5.083333   \n",
      "3       25449        8          3.60     3.433333     3.933333   \n",
      "4       19592        5          4.40     2.733333     3.233333   \n",
      "\n",
      "   self_direction  stimulation  hedonism     power  security  conformity  \\\n",
      "0        3.983333     1.983333  1.483333  2.983333  4.983333    3.983333   \n",
      "1        4.716667     2.716667  2.716667  2.716667  3.716667    2.716667   \n",
      "2        4.083333     2.583333  4.583333  2.083333  1.583333    4.083333   \n",
      "3        3.933333     1.933333  2.433333  4.933333  4.433333    2.933333   \n",
      "4        4.733333     3.733333  2.233333  3.233333  3.733333    4.233333   \n",
      "\n",
      "   tradition     p_avg  \n",
      "0   4.983333  4.516667  \n",
      "1   3.716667  4.783333  \n",
      "2   2.083333  3.916667  \n",
      "3   3.433333  4.566667  \n",
      "4   2.733333  4.766667  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(balanced_dataframe.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the (almost) balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_dataframe = undersampled_dataframe.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18782, 13)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_dataframe.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bin the data for each dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_lib (value):\n",
    "\n",
    "        if value < 3:\n",
    "            return 1#\"liberal\" #liberal\n",
    "        else:\n",
    "            return 0#\"moderate\" #moderate\n",
    "\n",
    "def normalise_con (value):\n",
    "        \n",
    "        if value > lrthreshold:\n",
    "            return 1#\"conservative\" #conservative\n",
    "        else:\n",
    "            return 0#\"moderate\" #moderate\n",
    "        \n",
    "\n",
    "lib_dataframe['lrscale'] = lib_dataframe['lrscale'].apply(normalise_lib)\n",
    "con_dataframe['lrscale'] = con_dataframe['lrscale'].apply(normalise_con)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: lrscale, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_lib = lib_dataframe.iloc[:, 2:12].copy()\n",
    "y_lib = lib_dataframe.iloc[:,1].copy()\n",
    "#Now the data frame for conservative prediction\n",
    "X_con = con_dataframe.iloc[:, 2:12].copy()\n",
    "y_con = con_dataframe.iloc[:,1].copy()\n",
    "\n",
    "print(y_con.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9391\n",
      "9391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list(y_con).count(1))\n",
    "print(list(y_con).count(0))\n",
    "\n",
    "con_lib_ratio = (list(y_con).count(1)/(list(y_con).count(0) + list(y_con).count(1)) * 100)\n",
    "con_lib_ratio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(sparse=False)\n",
    "y_lib_onehot = enc.fit_transform(y_lib.to_numpy().reshape(-1, 1))\n",
    "y_con_onehot = enc.fit_transform(y_con.to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Encoding instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_lib_onehot = label_encoder.fit_transform(y_lib.copy())\n",
    "y_con_onehot = label_encoder.fit_transform(y_con.copy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lib_oh, X_test_lib_oh, y_train_lib_oh, y_test_lib_oh = train_test_split(X_lib, y_lib_onehot, test_size=0.25, random_state=10)\n",
    "X_train_con_oh, X_test_con_oh, y_train_con_oh, y_test_con_oh = train_test_split(X_con, y_con_onehot, test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call this function to perform cross validation to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(model):\n",
    "    #return scores\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "      normalize=False, positive=False, precompute=False, random_state=None,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class Lasso():\n",
    "lasso_LIB_model = Lasso(alpha=1.0)\n",
    "#fitting the liberal model\n",
    "lasso_LIB_model.fit(X_train_lib_oh,y_train_lib_oh)\n",
    "\n",
    "lasso_CON_model = Lasso(alpha=1.0)\n",
    "lasso_CON_model.fit(X_train_con_oh,y_train_con_oh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49943206 0.50056794]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:434: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lasso_lib_pred = lasso_LIB_model.predict(X_test_lib_oh)\n",
    "# print(lasso_lib_pred)\n",
    "\n",
    "#enc.inverse_transform([np.argmax(lasso_lib_pred[0, :])])\n",
    "# #print(lasso_lib_pred[0, :])\n",
    "# print(\"The ground truth labels:\")\n",
    "# #print(np.argmax(y_test_lib_oh, axis = 1))\n",
    "# print(\"Liberal LASSO accuracy: \")\n",
    "# #print(accuracy_score(y_test_lib_oh, lasso_lib_pred))#np.argmax(y_test_lib_oh, axis = 1), np.argmax(lasso_LIB_model.predict(X_test_lib_oh), axis=1)))\n",
    "# print(lasso_LIB_model.coef_) #feature significance\n",
    "# print()\n",
    "# print(lasso_CON_model.predict(X_test_con_oh))\n",
    "# print(\"The ground truth labels:\")\n",
    "# print(y_test_con_oh)\n",
    "lasso_CON_model.score(X_test_con_oh,y_test_con_oh)\n",
    "print(lasso_CON_model.intercept_)\n",
    "#con_preds = lasso_CON_model.predict(X_test_con_oh)\n",
    "\n",
    "\n",
    "# enc.fit_transform(y_test_con_oh)\n",
    "\n",
    "#metrics_printer(enc.inverse_transform(y_test_con_oh),enc.invrse_transform(y_test_con_oh))\n",
    "\n",
    "# for i in con_preds:\n",
    "#     print(enc.inverse_transform(i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TIP: One hot encoding does not work well with Logistic Regression; a one hot encoding will case the matrix of input data to become singular, meaning it cannot be inverted and the linear regression coefficients cannot be calculated using linear algebra. For these types of models a dummy variable encoding must be used instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So: Label encoding the data for the Logistic Regression (and the Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lib_cat = y_lib.copy()        #NOT SURE WHAT THIS STEP DOES, MAYBE IT IS REDUNDANT\n",
    "y_con_cat = y_con.copy()\n",
    "\n",
    "# y_lib_cat = y_lib_cat.astype('category')\n",
    "# y_con_cat = y_con_cat.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_lib_labelencoded = label_encoder.fit_transform(y_lib_cat)\n",
    "y_con_labelencoded = label_encoder.fit_transform(y_con_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling (only for CONSERVATIVE PREDICTION for now)\n",
    "\n",
    "https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/\n",
    "\n",
    "https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/\n",
    "\n",
    "Random oversampling involves randomly duplicating examples from the minority class and adding them to the training dataset.\n",
    "\n",
    "Examples from the training dataset are selected randomly with replacement. This means that examples from the minority class can be chosen and added to the new “more balanced” training dataset multiple times; they are selected from the original training dataset, added to the new training dataset, and then returned or “replaced” in the original dataset, allowing them to be selected again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22.1\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler \n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lib_l, X_test_lib_l, y_train_lib_l, y_test_lib_l = train_test_split(X_lib, y_lib_labelencoded, test_size=0.30, random_state=10)\n",
    "X_train_con_l, X_test_con_l, y_train_con_l, y_test_con_l = train_test_split(X_con, y_con_labelencoded, test_size=0.30, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_LIB = LogisticRegression(random_state=0)\n",
    "logistic_regression_LIB.fit(X_train_lib_l, y_train_lib_l)\n",
    "\n",
    "logistic_regression_CON = LogisticRegression(random_state=0)\n",
    "logistic_regression_CON.fit(X_train_con_l, y_train_con_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liberal LR predicts:  [0 0 0 ... 0 0 0]\n",
      "Ground truth:  [1 0 0 ... 0 0 0]\n",
      "0.8825632563256326\n",
      "Conservative LR predicts: \n",
      "Ground truth:  [1 0 0 ... 0 0 1]\n",
      "0.5908111988513999\n",
      "\n",
      "LIBERAL COEFFICIENTS\n",
      "[[ 0.49919619 -0.04080791 -0.13054757 -0.09643039 -0.14987894 -0.08033117\n",
      "  -0.15718796 -0.19202133 -0.16193753 -0.18695461]]\n",
      "\n",
      "CONSERVATIVE COEFFICIENTS\n",
      "[[-0.46179378 -0.02419632 -0.0664999   0.04237721  0.07434872 -0.01327747\n",
      "   0.09786605  0.15873358  0.05412356  0.21810127]]\n",
      "CONSEVATIVE LOGISTIC REGRESSION - BALANCED - Threshold at 8 \n",
      "Accuracy:  0.5908111988513999\n",
      "Sensitivity:  0.6391304347826087\n",
      "Specificity:  0.5433854907539118\n"
     ]
    }
   ],
   "source": [
    "LR_lib_pred = logistic_regression_LIB.predict(X_test_lib_l)\n",
    "print(\"Liberal LR predicts: \",LR_lib_pred )\n",
    "print(\"Ground truth: \", y_test_lib_l)\n",
    "\n",
    "print(accuracy_score(y_test_lib_l, LR_lib_pred))\n",
    "\n",
    "LR_con_pred = logistic_regression_CON.predict(X_test_con_l)\n",
    "print(\"Conservative LR predicts: \", )\n",
    "print(\"Ground truth: \", y_test_con_l)\n",
    "print(accuracy_score(y_test_con_l, LR_con_pred))\n",
    "print()\n",
    "print(\"LIBERAL COEFFICIENTS\")\n",
    "print(logistic_regression_LIB.coef_)\n",
    "\n",
    "print()\n",
    "print(\"CONSERVATIVE COEFFICIENTS\")\n",
    "print(logistic_regression_CON.coef_)\n",
    "\n",
    "# Liberal LR predicts:  [0 0 0 ... 0 0 0]\n",
    "# Ground truth:  [1 0 0 ... 0 0 0]\n",
    "# 0.8820682068206821\n",
    "# Conservative LR predicts: \n",
    "# Ground truth:  [0 0 0 ... 0 1 0]\n",
    "# 0.7358635863586359\n",
    "\n",
    "\n",
    "metrics_printer(y_test_con_l, LR_con_pred, f\"CONSEVATIVE LOGISTIC REGRESSION - BALANCED - Threshold at {lrthreshold} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result interpretation:\n",
    "\n",
    "LIBERAL COEFFICIENTS\n",
    "[[ 0.64696149  0.10334159  0.00508842  0.03620765 -0.00407959  0.05359682\n",
    "  -0.02097152 -0.05334792 -0.013917   -0.057601  ]]\n",
    "\n",
    "CONSERVATIVE COEFFICIENTS\n",
    "[[-0.39614516  0.027852    0.03136662  0.11140505  0.06367177 -0.00044922\n",
    "   0.11708522  0.08849489  0.14891201  0.24233131]]\n",
    "   \n",
    "The external correlations match those given at https://gosling.psy.utexas.edu/wp-content/uploads/2016/12/Sandy-et-al-JPA-2016-Brief-values-measures.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix: \n",
    "Shows that the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liberal confusion matrix: \n",
      " [[9627    0]\n",
      " [1281    0]]\n",
      "conservative confusion matrix: \n",
      " [[916 683]\n",
      " [661 955]]\n"
     ]
    }
   ],
   "source": [
    "cm_lib = metrics.confusion_matrix(y_test_lib_l, LR_lib_pred)\n",
    "print(\"liberal confusion matrix: \\n\", cm_lib)\n",
    "\n",
    "cm_con = metrics.confusion_matrix(y_test_con_l, LR_con_pred)\n",
    "print(\"conservative confusion matrix: \\n\", cm_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88476348 0.88476348 0.88476348 0.88476348 0.88476348 0.88476348\n",
      " 0.88476348 0.88476348 0.8850385  0.8850385 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_LIB_CVVVVV = LogisticRegression(random_state=0)\n",
    "\n",
    "cv_results_lib = cross_validate(logistic_regression_LIB_CVVVVV, X_lib, y_lib_labelencoded, cv=10)\n",
    "\n",
    "cv_results_con = cross_validate(logistic_regression_CON, X_con, y_con_labelencoded, cv=3)\n",
    "\n",
    "print(cv_results_lib['test_score'])\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "… there are occasions when a complete set of dummy variables is useful. For example, the splits in a tree-based model are more interpretable when the dummy variables encode all the information for that predictor. We recommend using the full set if dummy variables when working with tree-based models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of liberal Random Forest  0.5145764576457645\n",
      "Accuracy of conservative Random Forest  0.5721464465183058\n"
     ]
    }
   ],
   "source": [
    "rf_lib = RandomForestClassifier(max_depth=None, random_state=0)\n",
    "rf_lib.fit(X_train_lib_l, y_train_lib_l)\n",
    "\n",
    "rf_con = RandomForestClassifier(max_depth= None, random_state=0)\n",
    "rf_lib.fit(X_train_con_l, y_train_con_l)\n",
    "\n",
    "\n",
    "rf_lib_predicted = rf_lib.predict(X_test_lib_l)\n",
    "rf_con_predicted = rf_lib.predict(X_test_con_l)\n",
    "\n",
    "print(\"Accuracy of liberal Random Forest \", accuracy_score(y_test_lib_l,rf_lib_predicted))\n",
    "print(\"Accuracy of conservative Random Forest \", accuracy_score(y_test_con_l,rf_con_predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liberal confusion matrix: \n",
      " [[5124 4503]\n",
      " [ 792  489]]\n",
      "conservative confusion matrix: \n",
      " [[397 306]\n",
      " [290 400]]\n"
     ]
    }
   ],
   "source": [
    "rf_cm_lib = metrics.confusion_matrix(y_test_lib_l, rf_lib_predicted)\n",
    "print(\"liberal confusion matrix: \\n\", rf_cm_lib)\n",
    "\n",
    "rf_cm_con = metrics.confusion_matrix(y_test_con_l, rf_con_predicted)\n",
    "print(\"conservative confusion matrix: \\n\", rf_cm_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Conservative - BALANCED DATA - threshold at 8\n",
      "Accuracy:  0.5721464465183058\n",
      "Sensitivity:  0.5797101449275363\n",
      "Specificity:  0.5647226173541963\n"
     ]
    }
   ],
   "source": [
    "metrics_printer(y_test_con_l, rf_con_predicted, f\"Random Forest Conservative - BALANCED DATA - threshold at {lrthreshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes (ToDo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lib_gnb = GaussianNB()\n",
    "\n",
    "lib_gnb.fit(X_train_lib_l, y_train_lib_l)\n",
    "\n",
    "\n",
    "con_gnb = GaussianNB()\n",
    "\n",
    "con_gnb.fit(X_train_con_l, y_train_con_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8735790245691236\n",
      "[[9454  173]\n",
      " [1206   75]]\n",
      "9454 173 1206 75\n",
      "0.7355152181884855\n",
      "[[7963   86]\n",
      " [2799   60]]\n"
     ]
    }
   ],
   "source": [
    "lib_gnb_predicted = lib_gnb.predict(X_test_lib_l)\n",
    "gnb_cm_lib = metrics.confusion_matrix(y_test_lib_l,lib_gnb_predicted)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test_lib_l,lib_gnb_predicted).ravel()\n",
    "\n",
    "con_gnb_predicted = con_gnb.predict(X_test_con_l)\n",
    "gnb_cm_con = metrics.confusion_matrix(y_test_con_l,con_gnb_predicted)\n",
    "print(accuracy_score(y_test_lib_l,lib_gnb_predicted))\n",
    "print(gnb_cm_lib)\n",
    "print(tn, fp, fn, tp)\n",
    "print(accuracy_score(y_test_con_l,con_gnb_predicted))\n",
    "print(gnb_cm_con)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection - experiments: \n",
    "*first attempt on the conservative classifier*\n",
    "\n",
    "Liberal significant features: \n",
    "\n",
    "Conservative significant features: Conformity, Tradition, Universalism, Self direction, Stimulation, Hedonism, Achievement (power), Security\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>universalism</th>\n",
       "      <th>achievement</th>\n",
       "      <th>self_direction</th>\n",
       "      <th>stimulation</th>\n",
       "      <th>hedonism</th>\n",
       "      <th>power</th>\n",
       "      <th>security</th>\n",
       "      <th>conformity</th>\n",
       "      <th>tradition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.50</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.80</td>\n",
       "      <td>4.133333</td>\n",
       "      <td>4.633333</td>\n",
       "      <td>3.133333</td>\n",
       "      <td>3.133333</td>\n",
       "      <td>3.133333</td>\n",
       "      <td>2.633333</td>\n",
       "      <td>2.133333</td>\n",
       "      <td>2.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.65</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>4.150000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>4.150000</td>\n",
       "      <td>2.650000</td>\n",
       "      <td>5.650000</td>\n",
       "      <td>2.650000</td>\n",
       "      <td>4.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.60</td>\n",
       "      <td>3.433333</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>2.933333</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>3.433333</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>2.433333</td>\n",
       "      <td>3.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.45</td>\n",
       "      <td>2.616667</td>\n",
       "      <td>4.116667</td>\n",
       "      <td>2.116667</td>\n",
       "      <td>5.116667</td>\n",
       "      <td>2.616667</td>\n",
       "      <td>2.616667</td>\n",
       "      <td>2.616667</td>\n",
       "      <td>3.616667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   universalism  achievement  self_direction  stimulation  hedonism     power  \\\n",
       "0          5.50     4.500000        4.000000     3.500000  3.000000  3.000000   \n",
       "1          4.80     4.133333        4.633333     3.133333  3.133333  3.133333   \n",
       "2          4.65     1.650000        4.150000     0.650000  4.150000  2.650000   \n",
       "3          3.60     3.433333        3.933333     2.933333  3.933333  3.433333   \n",
       "4          4.45     2.616667        4.116667     2.116667  5.116667  2.616667   \n",
       "\n",
       "   security  conformity  tradition  \n",
       "0  2.500000    1.000000   2.500000  \n",
       "1  2.633333    2.133333   2.633333  \n",
       "2  5.650000    2.650000   4.150000  \n",
       "3  3.933333    2.433333   3.933333  \n",
       "4  2.616667    2.616667   3.616667  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_con_featureslected = X_con.copy().drop(['benevolence'], axis = 1)\n",
    "\n",
    "X_con_featureslected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_con_oh_fs, X_test_con_oh_fs, y_train_con_oh_fs, y_test_con_oh_fs = train_test_split(X_con_featureslected, y_con_onehot, test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_con_gnb = GaussianNB()\n",
    "\n",
    "fs_con_gnb.fit(X_train_con_oh_fs, y_train_con_oh_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6657   34 2378   21]\n",
      "0.7346534653465346\n",
      "[0 0 0 ... 0 0 0]\n",
      "[[6657   34]\n",
      " [2378   21]]\n",
      "9035\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "fs_con_gnb_predicted = fs_con_gnb.predict(X_test_con_oh_fs)\n",
    "fs_gnb_cm_con = metrics.confusion_matrix(y_test_con_oh_fs,fs_con_gnb_predicted)\n",
    "print(metrics.confusion_matrix(y_test_con_oh_fs,fs_con_gnb_predicted).ravel())\n",
    "print(accuracy_score(y_test_con_oh_fs,fs_con_gnb_predicted))\n",
    "\n",
    "print(label_encoder.inverse_transform(fs_con_gnb_predicted))\n",
    "print(metrics.confusion_matrix(y_test_con_oh_fs,fs_con_gnb_predicted))\n",
    "\n",
    "print(list(fs_con_gnb_predicted).count(0))\n",
    "print(list(label_encoder.inverse_transform(fs_con_gnb_predicted)).count('conservative'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations: \n",
    "(with normalisations of conservatives over 7 (i.e. > 7)\n",
    "- NB using OneHot encoding and having removed Benevolence: 93% accuracy\n",
    "[   2  605]\n",
    " [   4 8479]]\n",
    " \n",
    "- NB using OneHot encoding and having removed Benevelonece & Power: 93% accuracy\n",
    "[[   0  607]\n",
    " [   2 8481]]\n",
    "\n",
    "-  NB using Label encoding and having removed Benevolence: 84.8% accuracy\n",
    "[[  10 1370]\n",
    " [   8 7702]]\n",
    " \n",
    "- NB using Label encoding and having removed Benevolence & Power: 84.8%\n",
    "[[   6 1374]\n",
    " [   3 7707]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_rf_con = RandomForestClassifier(max_depth=None, random_state=0)\n",
    "fs_rf_con.fit(X_train_con_oh_fs, y_train_con_oh_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7346534653465346\n",
      "[[6657   34]\n",
      " [2378   21]]\n"
     ]
    }
   ],
   "source": [
    "fs_rf_con_predicted = fs_con_gnb.predict(X_test_con_oh_fs)\n",
    "print(accuracy_score(y_test_con_oh_fs,fs_rf_con_predicted))\n",
    "print(metrics.confusion_matrix(y_test_con_oh_fs,fs_rf_con_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking Algorithms\n",
    "\n",
    "- Training data consists of lists of items with some partial order specified between items in each list. This order is typically induced by giving a numerical or ordinal score or a binary judgment (e.g. \"relevant\" or \"not relevant\") for each item. The ranking model purposes to rank, i.e. producing a permutation of items in new, unseen lists in a similar way to rankings in the training data.\n",
    "\n",
    "Ideas: \n",
    "    - Rank based on 'higher value = most important' (i.e. based on the assumption that conservatives have similar higher values  and similar lower values)\n",
    "    - Rank based  on ''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lib_RANK1 = X_lib.copy()\n",
    "X_con_RANK1 = X_con.copy()\n",
    "\n",
    "# X_lib_RANK1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_value (dataframe):\n",
    "    df = dataframe.copy()\n",
    "    df_comps = pd.DataFrame()\n",
    "    col_name =''\n",
    "    for column_name, data in df.iteritems():\n",
    "        for other_column_name, other_data in df.iteritems():\n",
    "            if column_name != other_column_name:\n",
    "                comp_col_name = column_name + ' < ' + other_column_name\n",
    "                df_comps[comp_col_name] = df[column_name] < df[other_column_name]\n",
    "\n",
    "    return df_comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_con_RANK = relative_value(X_con_RANK1)\n",
    "X_lib_RANK = X_con_RANK.copy()\n",
    "\n",
    "len(X_lib_RANK.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_lib = lib_dataframe.iloc[:, 2:12].copy()\n",
    "# y_lib = lib_dataframe.iloc[:,1].copy()\n",
    "# #Now the data frame for conservative prediction\n",
    "# X_con = con_dataframe.iloc[:, 2:12].copy()\n",
    "# y_con = con_dataframe.iloc[:,1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_lib_labelencoded = label_encoder.fit_transform(y_lib)\n",
    "y_con_labelencoded = label_encoder.fit_transform(y_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(sparse=False)\n",
    "y_lib_onehot = enc.fit_transform(y_lib.to_numpy().reshape(-1, 1))\n",
    "y_con_onehot = enc.fit_transform(y_con.to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lib, X_test_lib, y_train_lib, y_test_lib = train_test_split(X_lib_RANK, y_lib_labelencoded, test_size=0.30, random_state=10)\n",
    "X_train_con, X_test_con, y_train_con, y_test_con = train_test_split(X_con_RANK, y_con_labelencoded, test_size=0.30, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8049"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y_test_con).count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_printer (ground_truth, model_predicted, classification_target = None):\n",
    "    \"\"\"Return sensitivity,specificity,accuracy & if given classification target\"\"\"\n",
    "    if classification_target != None: \n",
    "        print(classification_target)\n",
    "    tnegative, fpositive, fnegative, tpositive = metrics.confusion_matrix(ground_truth,model_predicted).ravel()\n",
    "    print(\"Accuracy: \", accuracy_score(ground_truth,model_predicted))\n",
    "    print(\"Sensitivity: \", sensitivity(tpositive,fnegative))\n",
    "    print(\"Specificity: \", specificity(tnegative,fpositive))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_gnb_RANK = GaussianNB()\n",
    "con_gnb_RANK.fit(X_train_con, y_train_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6417308397506417\n",
      "Sensitivity:  0.36096537250786986\n",
      "Specificity:  0.7414585662815256\n"
     ]
    }
   ],
   "source": [
    "con_RANK_predicted = con_gnb_RANK.predict(X_test_con)\n",
    "# print(type(con_RANK_predicted))\n",
    "# print(accuracy_score(y_test_con,con_RANK_predicted))\n",
    "# tnegative, fpositive, fnegative, tpositive = metrics.confusion_matrix(y_test_con,con_RANK_predicted).ravel()\n",
    "# print(\"tn\",tnegative, \"fp\",fpositive, \"fn\",fnegative,\"tp\", tpositive)\n",
    "# print(metrics.confusion_matrix(y_test_con,con_RANK_predicted))\n",
    "\n",
    "# sensitivity(tpositive,fnegative)\n",
    "# specificity(tnegative,fpositive)\n",
    "\n",
    "# (TP / (TP + FN))\n",
    "# (TN / (TN + FP))\n",
    "\n",
    "metrics_printer(y_test_con,con_RANK_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"LIBERAL NB RANKED\"\"\"\n",
    "\n",
    "lib_gnb_RANK = GaussianNB()\n",
    "#X_train_lib, X_test_lib, y_train_lib, y_test_lib\n",
    "lib_gnb_RANK.fit(X_train_lib, y_train_lib)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_rank_predicted = lib_gnb_RANK.predict(X_test_lib)\n",
    "metrics_printer(y_test_lib,lib_rank_predicted,\"Liberal Ranked NB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lib_rank_predicted)\n",
    "print(label_encoder.inverse_transform(lib_rank_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_con_RANK = RandomForestClassifier(max_depth= None, random_state=0)\n",
    "rf_con_RANK.fit(X_train_con, y_train_con)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of conservative Random Forest  0.7162632929959662\n",
      "[[7624  425]\n",
      " [2670  189]]\n",
      "Accuracy:  0.7162632929959662\n",
      "Sensitivity:  0.06610703043022036\n",
      "Specificity:  0.9471984097403404\n"
     ]
    }
   ],
   "source": [
    "rf_con_RANK_predicted = rf_con_RANK.predict(X_test_con)\n",
    "\n",
    "\n",
    "print(\"Accuracy of conservative Random Forest \", accuracy_score(y_test_con,rf_con_RANK_predicted))\n",
    "\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test_con,rf_con_RANK_predicted).ravel()\n",
    "\n",
    "print(metrics.confusion_matrix(y_test_con,rf_con_RANK_predicted))\n",
    "\n",
    "# print(\"tn\",tn, \"fp\",fp, \"fn\",fn,\"tp\", tp)\n",
    "\n",
    "metrics_printer(y_test_con,rf_con_RANK_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics_printer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-8f56b55b3fef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmetrics_printer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_con\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrf_con_RANK_predicted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Conservative RF\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# print(rf_con_RANK_predicted)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# print(label_encoder.inverse_transform(rf_con_RANK_predicted))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics_printer' is not defined"
     ]
    }
   ],
   "source": [
    "metrics_printer(y_test_con,rf_con_RANK_predicted,\"Conservative RF\")\n",
    "# print(rf_con_RANK_predicted)\n",
    "# print(label_encoder.inverse_transform(rf_con_RANK_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest:\n",
    "_Normalistion point @ 8_\n",
    "Accuracy of conservative Random Forest  0.9242757609094243\n",
    "\n",
    "Sensitivity = 0.9872486512996567\n",
    "Specificity = 0.023842917251051893\n",
    "\n",
    "[   17   696]\n",
    "[  130 10065]\n",
    "\n",
    "---------------------------------------------------------------\n",
    " \n",
    "_Normalisation point @ 7_\n",
    "Accuracy of conservative Random Forest  0.8423175650898423\n",
    "\n",
    "Sensitivity = 0.9872803708095289\n",
    "Specificity = 0.04595879556259905\n",
    "\n",
    "[  29 1602]\n",
    "[ 118 9159]\n",
    "\n",
    "---------------------------------------------------------------\n",
    " \n",
    "_Normalisatin point @ 6\n",
    "Accuracy of conservative Random Forest  0.7326732673267327\n",
    "\n",
    "Sensitivity = 0.9873276183376817\n",
    "Specificity = 0.015739769150052464\n",
    "\n",
    "[  45 2814]\n",
    "[ 102 7947]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-e34a0a8b260f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mAccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mTN\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mTN\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mSensitivity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTP\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mSpecificity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTN\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTN\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TP' is not defined"
     ]
    }
   ],
   "source": [
    "Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "Sensitivity = TP / (TP + FN)\n",
    "Specificity = TN / (TN + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity(TP, FN):\n",
    "    sensitivity = (TP / (TP + FN))\n",
    "   # print(sensitivity)\n",
    "    return sensitivity\n",
    "\n",
    "def specificity (TN, FP):\n",
    "    specificity = (TN / (TN + FP))\n",
    "   # print(specificity)\n",
    "    return specificity\n",
    "\n",
    "# print(sensitivity(tp,fn))\n",
    "# print(specificity( tn,fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
